<!DOCTYPE html>
<html class="client-nojs" lang="de" dir="ltr">
<head>
<meta charset="UTF-8"/>
<title>Künstliches neuronales Netz – Wikipedia</title>
<script>document.documentElement.className = document.documentElement.className.replace( /(^|\s)client-nojs(\s|$)/, "$1client-js$2" );</script>
<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":false,"wgNamespaceNumber":0,"wgPageName":"Künstliches_neuronales_Netz","wgTitle":"Künstliches neuronales Netz","wgCurRevisionId":187559803,"wgRevisionId":187559803,"wgArticleId":26775,"wgIsArticle":true,"wgIsRedirect":false,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["Wikipedia:Defekte Weblinks/Ungeprüfte Archivlinks 2018-11","Neuroinformatik","Künstliche Neuronale Netze","Regressionsanalyse","Klassifikationsverfahren"],"wgBreakFrames":false,"wgPageContentLanguage":"de","wgPageContentModel":"wikitext","wgSeparatorTransformTable":[",\t.",".\t,"],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","Januar","Februar","März","April","Mai","Juni","Juli","August","September","Oktober","November","Dezember"],"wgMonthNamesShort":["","Jan.","Feb.","Mär.","Apr.","Mai","Jun.","Jul.","Aug.","Sep.","Okt.","Nov.","Dez."],"wgRelevantPageName":"Künstliches_neuronales_Netz","wgRelevantArticleId":26775,"wgRequestId":"XMhpTQpAMEsAAGwwriwAAABV","wgCSPNonce":false,"wgIsProbablyEditable":true,"wgRelevantPageIsProbablyEditable":true,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgFlaggedRevsParams":{"tags":{"accuracy":{"levels":1,"quality":2,"pristine":4}}},"wgStableRevisionId":187559803,"wgMediaViewerOnClick":true,"wgMediaViewerEnabledByDefault":true,"wgPopupsReferencePreviews":false,"wgPopupsConflictsWithNavPopupGadget":false,"wgVisualEditor":{"pageLanguageCode":"de","pageLanguageDir":"ltr","pageVariantFallbacks":"de","usePageImages":true,"usePageDescriptions":true},"wgMFDisplayWikibaseDescriptions":{"search":true,"nearby":true,"watchlist":true,"tagline":true},"wgRelatedArticles":null,"wgRelatedArticlesUseCirrusSearch":true,"wgRelatedArticlesOnlyUseCirrusSearch":false,"wgWMESchemaEditAttemptStepOversample":false,"wgPoweredByHHVM":true,"wgULSCurrentAutonym":"Deutsch","wgNoticeProject":"wikipedia","wgCentralNoticeCookiesToDelete":[],"wgCentralNoticeCategoriesUsingLegacy":["Fundraising","fundraising"],"wgWikibaseItemId":"Q192776","wgCentralAuthMobileDomain":false,"wgEditSubmitButtonLabelPublish":true});mw.loader.state({"ext.globalCssJs.user.styles":"ready","ext.globalCssJs.site.styles":"ready","site.styles":"ready","noscript":"ready","user.styles":"ready","ext.globalCssJs.user":"ready","ext.globalCssJs.site":"ready","user":"ready","user.options":"loading","user.tokens":"loading","ext.math.styles":"ready","ext.cite.styles":"ready","mediawiki.legacy.shared":"ready","mediawiki.legacy.commonPrint":"ready","mediawiki.toc.styles":"ready","wikibase.client.init":"ready","ext.visualEditor.desktopArticleTarget.noscript":"ready","ext.uls.interlanguage":"ready","ext.wikimediaBadges":"ready","ext.3d.styles":"ready","ext.flaggedRevs.basic":"ready","mediawiki.skinning.interface":"ready","skins.vector.styles":"ready"});mw.loader.implement("user.options@1wzrrbt",function($,jQuery,require,module){/*@nomin*/mw.user.options.set({"variant":"de"});
});mw.loader.implement("user.tokens@0tffind",function($,jQuery,require,module){/*@nomin*/mw.user.tokens.set({"editToken":"+\\","patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});
});RLPAGEMODULES=["ext.math.scripts","ext.cite.ux-enhancements","site","mediawiki.page.startup","mediawiki.page.ready","mediawiki.toc","mediawiki.searchSuggest","ext.gadget.editMenus","ext.gadget.WikiMiniAtlas","ext.gadget.OpenStreetMap","ext.gadget.CommonsDirekt","ext.centralauth.centralautologin","mmv.head","mmv.bootstrap.autostart","ext.popups","ext.visualEditor.desktopArticleTarget.init","ext.visualEditor.targetLoader","ext.eventLogging","ext.wikimediaEvents","ext.navigationTiming","ext.uls.eventlogger","ext.uls.init","ext.uls.compactlinks","ext.uls.interface","ext.centralNotice.geoIP","ext.centralNotice.startUp","ext.flaggedRevs.advanced","skins.vector.js"];mw.loader.load(RLPAGEMODULES);});</script>
<link rel="stylesheet" href="/w/load.php?lang=de&amp;modules=ext.3d.styles%7Cext.cite.styles%7Cext.flaggedRevs.basic%7Cext.math.styles%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikimediaBadges%7Cmediawiki.legacy.commonPrint%2Cshared%7Cmediawiki.skinning.interface%7Cmediawiki.toc.styles%7Cskins.vector.styles%7Cwikibase.client.init&amp;only=styles&amp;skin=vector"/>
<script async="" src="/w/load.php?lang=de&amp;modules=startup&amp;only=scripts&amp;skin=vector"></script>
<meta name="ResourceLoaderDynamicStyles" content=""/>
<link rel="stylesheet" href="/w/load.php?lang=de&amp;modules=site.styles&amp;only=styles&amp;skin=vector"/>
<meta name="generator" content="MediaWiki 1.34.0-wmf.1"/>
<meta name="referrer" content="origin"/>
<meta name="referrer" content="origin-when-crossorigin"/>
<meta name="referrer" content="origin-when-cross-origin"/>
<meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/thumb/3/3d/Neural_network.svg/1200px-Neural_network.svg.png"/>
<link rel="alternate" href="android-app://org.wikipedia/http/de.m.wikipedia.org/wiki/K%C3%BCnstliches_neuronales_Netz"/>
<link rel="alternate" type="application/x-wiki" title="Seite bearbeiten" href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;action=edit"/>
<link rel="edit" title="Seite bearbeiten" href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;action=edit"/>
<link rel="apple-touch-icon" href="/static/apple-touch/wikipedia.png"/>
<link rel="shortcut icon" href="/static/favicon/wikipedia.ico"/>
<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (de)"/>
<link rel="EditURI" type="application/rsd+xml" href="//de.wikipedia.org/w/api.php?action=rsd"/>
<link rel="license" href="//creativecommons.org/licenses/by-sa/3.0/"/>
<link rel="canonical" href="https://de.wikipedia.org/wiki/K%C3%BCnstliches_neuronales_Netz"/>
<link rel="dns-prefetch" href="//login.wikimedia.org"/>
<link rel="dns-prefetch" href="//meta.wikimedia.org" />
<!--[if lt IE 9]><script src="/w/load.php?lang=qqx&amp;modules=html5shiv&amp;only=scripts&amp;skin=fallback&amp;sync=1"></script><![endif]-->
</head>
<body class="mediawiki ltr sitedir-ltr capitalize-all-nouns mw-hide-empty-elt ns-0 ns-subject mw-editable page-Künstliches_neuronales_Netz rootpage-Künstliches_neuronales_Netz skin-vector action-view">
<div id="mw-page-base" class="noprint"></div>
<div id="mw-head-base" class="noprint"></div>
<div id="content" class="mw-body" role="main">
	<a id="top"></a>
	<div id="siteNotice" class="mw-body-content"><!-- CentralNotice --></div>
	<div class="mw-indicators mw-body-content">
</div>

	<h1 id="firstHeading" class="firstHeading" lang="de">Künstliches neuronales Netz</h1>
	
	<div id="bodyContent" class="mw-body-content">
		<div id="siteSub" class="noprint">aus Wikipedia, der freien Enzyklop&auml;die</div>
		<div id="contentSub"></div>
		
		
		
		<div id="jump-to-nav"></div>
		<a class="mw-jump-link" href="#mw-head">Zur Navigation springen</a>
		<a class="mw-jump-link" href="#p-search">Zur Suche springen</a>
		<div id="mw-content-text" lang="de" dir="ltr" class="mw-content-ltr"><div class="mw-parser-output"><p><b>Künstliche neuronale Netze</b>, auch <b>künstliche neuronale Netzwerke</b>, kurz: <i>KNN</i> (englisch <i>artificial neural network</i>, ANN), sind Netze aus <a href="/wiki/K%C3%BCnstliches_Neuron" title="Künstliches Neuron">künstlichen Neuronen</a>. Sie sind Forschungsgegenstand der <a href="/wiki/Neuroinformatik" title="Neuroinformatik">Neuroinformatik</a> und stellen einen Zweig der <a href="/wiki/K%C3%BCnstliche_Intelligenz" title="Künstliche Intelligenz">künstlichen Intelligenz</a> dar.
</p>
<div class="thumb tright"><div class="thumbinner" style="width:222px;"><a href="/wiki/Datei:Neural_network.svg" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/3/3d/Neural_network.svg/220px-Neural_network.svg.png" decoding="async" width="220" height="138" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/3/3d/Neural_network.svg/330px-Neural_network.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/3/3d/Neural_network.svg/440px-Neural_network.svg.png 2x" data-file-width="1024" data-file-height="640" /></a>  <div class="thumbcaption"><div class="magnify"><a href="/wiki/Datei:Neural_network.svg" class="internal" title="vergrößern und Informationen zum Bild anzeigen"></a></div>Vereinfachte Darstellung eines künstlichen neuronalen Netzes</div></div></div>
<div class="thumb tright"><div class="thumbinner" style="width:222px;"><a href="/wiki/Datei:ArtificialNeuronModel_deutsch.png" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/7/7f/ArtificialNeuronModel_deutsch.png/220px-ArtificialNeuronModel_deutsch.png" decoding="async" width="220" height="105" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/7/7f/ArtificialNeuronModel_deutsch.png/330px-ArtificialNeuronModel_deutsch.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/7/7f/ArtificialNeuronModel_deutsch.png/440px-ArtificialNeuronModel_deutsch.png 2x" data-file-width="1682" data-file-height="799" /></a>  <div class="thumbcaption"><div class="magnify"><a href="/wiki/Datei:ArtificialNeuronModel_deutsch.png" class="internal" title="vergrößern und Informationen zum Bild anzeigen"></a></div>Schema für ein <a href="/wiki/K%C3%BCnstliches_Neuron" title="Künstliches Neuron">künstliches Neuron</a></div></div></div>
<p>Künstliche neuronale Netze haben, ebenso wie künstliche Neuronen, ein biologisches Vorbild. Man stellt sie natürlichen <a href="/wiki/Neuronales_Netz" title="Neuronales Netz">neuronalen Netzen</a> gegenüber, die eine Vernetzung von <a href="/wiki/Nervenzelle" title="Nervenzelle">Neuronen</a> im <a href="/wiki/Nervensystem" title="Nervensystem">Nervensystem</a> eines Lebewesens darstellen. Bei KNNs geht es allerdings mehr um eine Abstraktion (<a href="/wiki/Modell" title="Modell">Modellbildung</a>) von Informationsverarbeitung, weniger um das Nachbilden biologischer neuronaler Netze und Neuronen, was eher Gegenstand der <i><a href="/wiki/Computational_Neuroscience" title="Computational Neuroscience">Computational Neuroscience</a></i> ist.
</p>
<div id="toc" class="toc"><input type="checkbox" role="button" id="toctogglecheckbox" class="toctogglecheckbox" style="display:none" /><div class="toctitle" lang="de" dir="ltr"><h2>Inhaltsverzeichnis</h2><span class="toctogglespan"><label class="toctogglelabel" for="toctogglecheckbox"></label></span></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#Beschreibung"><span class="tocnumber">1</span> <span class="toctext">Beschreibung</span></a></li>
<li class="toclevel-1 tocsection-2"><a href="#Geschichtliche_Entwicklung"><span class="tocnumber">2</span> <span class="toctext">Geschichtliche Entwicklung</span></a>
<ul>
<li class="toclevel-2 tocsection-3"><a href="#Anfänge"><span class="tocnumber">2.1</span> <span class="toctext">Anfänge</span></a></li>
<li class="toclevel-2 tocsection-4"><a href="#Erste_Blütezeit"><span class="tocnumber">2.2</span> <span class="toctext">Erste Blütezeit</span></a></li>
<li class="toclevel-2 tocsection-5"><a href="#Langsamer_Wiederaufbau"><span class="tocnumber">2.3</span> <span class="toctext">Langsamer Wiederaufbau</span></a></li>
<li class="toclevel-2 tocsection-6"><a href="#Renaissance"><span class="tocnumber">2.4</span> <span class="toctext">Renaissance</span></a></li>
<li class="toclevel-2 tocsection-7"><a href="#Neue_Erfolge_in_Mustererkennungswettbewerben_seit_2009"><span class="tocnumber">2.5</span> <span class="toctext">Neue Erfolge in Mustererkennungswettbewerben seit 2009</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-8"><a href="#Topologie_der_Verbindungsnetzwerke"><span class="tocnumber">3</span> <span class="toctext">Topologie der Verbindungsnetzwerke</span></a>
<ul>
<li class="toclevel-2 tocsection-9"><a href="#Typische_Strukturen"><span class="tocnumber">3.1</span> <span class="toctext">Typische Strukturen</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-10"><a href="#Anwendung"><span class="tocnumber">4</span> <span class="toctext">Anwendung</span></a></li>
<li class="toclevel-1 tocsection-11"><a href="#Biologische_Motivation"><span class="tocnumber">5</span> <span class="toctext">Biologische Motivation</span></a></li>
<li class="toclevel-1 tocsection-12"><a href="#Klassen_und_Typen_von_KNN"><span class="tocnumber">6</span> <span class="toctext">Klassen und Typen von KNN</span></a></li>
<li class="toclevel-1 tocsection-13"><a href="#Aktivierungsfunktion"><span class="tocnumber">7</span> <span class="toctext">Aktivierungsfunktion</span></a></li>
<li class="toclevel-1 tocsection-14"><a href="#Lernverfahren"><span class="tocnumber">8</span> <span class="toctext">Lernverfahren</span></a>
<ul>
<li class="toclevel-2 tocsection-15"><a href="#Überwachtes_Lernen_(supervised_learning)"><span class="tocnumber">8.1</span> <span class="toctext">Überwachtes Lernen (supervised learning)</span></a></li>
<li class="toclevel-2 tocsection-16"><a href="#Unüberwachtes_Lernen_(unsupervised_learning)"><span class="tocnumber">8.2</span> <span class="toctext">Unüberwachtes Lernen (unsupervised learning)</span></a></li>
<li class="toclevel-2 tocsection-17"><a href="#Bestärkendes_Lernen_(reinforced_learning)"><span class="tocnumber">8.3</span> <span class="toctext">Bestärkendes Lernen (reinforced learning)</span></a></li>
<li class="toclevel-2 tocsection-18"><a href="#Stochastisches_Lernen"><span class="tocnumber">8.4</span> <span class="toctext">Stochastisches Lernen</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-19"><a href="#Allgemeine_Probleme"><span class="tocnumber">9</span> <span class="toctext">Allgemeine Probleme</span></a></li>
<li class="toclevel-1 tocsection-20"><a href="#Filmische_Dokumentationen"><span class="tocnumber">10</span> <span class="toctext">Filmische Dokumentationen</span></a></li>
<li class="toclevel-1 tocsection-21"><a href="#Siehe_auch"><span class="tocnumber">11</span> <span class="toctext">Siehe auch</span></a></li>
<li class="toclevel-1 tocsection-22"><a href="#Literatur"><span class="tocnumber">12</span> <span class="toctext">Literatur</span></a></li>
<li class="toclevel-1 tocsection-23"><a href="#Weblinks"><span class="tocnumber">13</span> <span class="toctext">Weblinks</span></a>
<ul>
<li class="toclevel-2 tocsection-24"><a href="#Implementierungen_und_Simulationspakete"><span class="tocnumber">13.1</span> <span class="toctext">Implementierungen und Simulationspakete</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-25"><a href="#Einzelnachweise"><span class="tocnumber">14</span> <span class="toctext">Einzelnachweise</span></a></li>
</ul>
</div>

<h2><span class="mw-headline" id="Beschreibung">Beschreibung</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;veaction=edit&amp;section=1" class="mw-editsection-visualeditor" title="Abschnitt bearbeiten: Beschreibung">Bearbeiten</a><span class="mw-editsection-divider"> | </span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;action=edit&amp;section=1" title="Abschnitt bearbeiten: Beschreibung">Quelltext bearbeiten</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Künstliche neuronale Netze basieren meist auf der Vernetzung vieler <a href="/wiki/McCulloch-Pitts-Zelle" title="McCulloch-Pitts-Zelle">McCulloch-Pitts-Neuronen</a> oder leichter Abwandlungen davon. Grundsätzlich können auch andere künstliche Neuronen Anwendung in KNNen finden, z.&#160;B. das <a href="/w/index.php?title=High-Order-Neuron&amp;action=edit&amp;redlink=1" class="new" title="High-Order-Neuron (Seite nicht vorhanden)">High-Order-Neuron</a>. Die <a href="/wiki/Topologie_(K%C3%BCnstliche_neuronale_Netze)" class="mw-redirect" title="Topologie (Künstliche neuronale Netze)">Topologie</a> eines Netzes (die Zuordnung von Verbindungen zu Knoten) muss abhängig von seiner Aufgabe gut durchdacht sein. Nach der Konstruktion eines Netzes folgt die Trainingsphase, in der das Netz „lernt“. Theoretisch kann ein Netz durch folgende Methoden lernen:
</p>
<ul><li>Entwicklung neuer Verbindungen</li>
<li>Löschen existierender Verbindungen</li>
<li>Ändern der <a href="/wiki/Gewichtung" title="Gewichtung">Gewichtung</a> (der Gewichte <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle w_{ij}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>w</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mi>j</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle w_{ij}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d3302ff355269436b43bc2fbe180303881c09321" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:3.141ex; height:2.343ex;" alt="w_{{ij}}"/></span> von Neuron <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle j}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>j</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle j}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2f461e54f5c093e92a55547b9764291390f0b5d0" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; margin-left: -0.027ex; width:0.985ex; height:2.509ex;" alt="j"/></span> zu Neuron <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle i}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>i</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle i}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/add78d8608ad86e54951b8c8bd6c8d8416533d20" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:0.802ex; height:2.176ex;" alt="i"/></span>)</li>
<li>Anpassen der <a href="/wiki/Schwellenwert_(Elektronik)" title="Schwellenwert (Elektronik)">Schwellenwerte</a> der Neuronen, sofern diese Schwellwerte besitzen</li>
<li>Hinzufügen oder Löschen von Neuronen</li>
<li>Modifikation von Aktivierungs-, Propagierungs- oder Ausgabefunktion</li></ul>
<p>Außerdem verändert sich das Lernverhalten bei Veränderung der <a href="/wiki/Aktivierungsfunktion" class="mw-redirect" title="Aktivierungsfunktion">Aktivierungsfunktion</a> der Neuronen oder der Lernrate des Netzes. Praktisch gesehen „lernt“ ein Netz hauptsächlich durch Modifikation der Gewichte der Neuronen. Eine Anpassung des Schwellwertes kann hierbei durch ein <a href="/wiki/K%C3%BCnstliches_Neuron#on-Neuron" title="Künstliches Neuron">on-Neuron</a> miterledigt werden. Dadurch sind KNNs in der Lage, komplizierte <a href="/wiki/Nichtlinear" class="mw-redirect" title="Nichtlinear">nichtlineare</a> <a href="/wiki/Funktion_(Mathematik)" title="Funktion (Mathematik)">Funktionen</a> über einen „Lern“-<a href="/wiki/Algorithmus" title="Algorithmus">Algorithmus</a>, der durch <a href="/wiki/Iteration" title="Iteration">iterative</a> oder <a href="/wiki/Rekursiv" class="mw-redirect" title="Rekursiv">rekursive</a> Vorgehensweise aus vorhandenen Ein- und gewünschten Ausgangswerten alle <a href="/wiki/Parameter_(Mathematik)" title="Parameter (Mathematik)">Parameter</a> der Funktion zu bestimmen versucht, zu erlernen. KNNs sind dabei eine Realisierung des <a href="/wiki/Konnektionismus" title="Konnektionismus">konnektionistischen</a> <a href="/wiki/Paradigma" title="Paradigma">Paradigmas</a>, da die Funktion aus vielen einfachen gleichartigen Teilen besteht. Erst in ihrer Summe wird das Verhalten komplex. Neuronale Netze stellen von der <a href="/wiki/Berechenbarkeit" title="Berechenbarkeit">Berechenbarkeit</a> her ein äquivalentes Modell zur <a href="/wiki/Turingmaschine" title="Turingmaschine">Turingmaschine</a> dar.<sup id="cite_ref-1" class="reference"><a href="#cite_note-1">&#91;1&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Geschichtliche_Entwicklung">Geschichtliche Entwicklung</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;veaction=edit&amp;section=2" class="mw-editsection-visualeditor" title="Abschnitt bearbeiten: Geschichtliche Entwicklung">Bearbeiten</a><span class="mw-editsection-divider"> | </span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;action=edit&amp;section=2" title="Abschnitt bearbeiten: Geschichtliche Entwicklung">Quelltext bearbeiten</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Das Interesse für künstliche neuronale Netze setzte bereits in den frühen <a href="/wiki/1940er" title="1940er">1940er</a> Jahren ein, also etwa gleichzeitig mit dem Einsatz programmierbarer Computer in angewandter Mathematik.<sup id="cite_ref-2" class="reference"><a href="#cite_note-2">&#91;2&#93;</a></sup>
</p>
<h3><span id="Anf.C3.A4nge"></span><span class="mw-headline" id="Anfänge">Anfänge</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;veaction=edit&amp;section=3" class="mw-editsection-visualeditor" title="Abschnitt bearbeiten: Anfänge">Bearbeiten</a><span class="mw-editsection-divider"> | </span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;action=edit&amp;section=3" title="Abschnitt bearbeiten: Anfänge">Quelltext bearbeiten</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Die Anfänge gehen auf <a href="/wiki/Warren_McCulloch" title="Warren McCulloch">Warren McCulloch</a> und <a href="/wiki/Walter_Pitts" title="Walter Pitts">Walter Pitts</a> zurück. Diese beschreiben 1943 Verknüpfungen von elementaren Einheiten als eine der Vernetzung von Neuronen ähnliche Art von Netzwerk, mit dem sich praktisch jede logische oder arithmetische Funktion berechnen lassen könnte<sup id="cite_ref-3" class="reference"><a href="#cite_note-3">&#91;3&#93;</a></sup>. 1947 weisen sie darauf hin, dass ein solches Netz beispielsweise zur räumlichen Mustererkennung eingesetzt werden kann. 1949 formuliert <a href="/wiki/Donald_O._Hebb" title="Donald O. Hebb">Donald O. Hebb</a> seine <a href="/wiki/Hebbsche_Lernregel" title="Hebbsche Lernregel">Hebbsche Lernregel</a>, die in ihrer allgemeinen Form die meisten der künstlichen neuronalen Lernverfahren darstellt. <a href="/wiki/Karl_Lashley" title="Karl Lashley">Karl Lashley</a> kommt 1950 zu der These, dass der Prozess der Informationsspeicherung im Gehirn verteilt auf verschiedene Untereinheiten realisiert wird.<sup id="cite_ref-chemgapedia_4-0" class="reference"><a href="#cite_note-chemgapedia-4">&#91;4&#93;</a></sup>
</p>
<h3><span id="Erste_Bl.C3.BCtezeit"></span><span class="mw-headline" id="Erste_Blütezeit">Erste Blütezeit</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;veaction=edit&amp;section=4" class="mw-editsection-visualeditor" title="Abschnitt bearbeiten: Erste Blütezeit">Bearbeiten</a><span class="mw-editsection-divider"> | </span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;action=edit&amp;section=4" title="Abschnitt bearbeiten: Erste Blütezeit">Quelltext bearbeiten</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Im anschließenden Jahr, 1951, gelingt <a href="/wiki/Marvin_Minsky" title="Marvin Minsky">Marvin Minsky</a> mit seiner Dissertationsarbeit der Bau des Neurocomputers <i>Snarc</i>, der seine Gewichte automatisch justieren kann, jedoch nicht praktisch einsetzbar ist.<sup id="cite_ref-chemgapedia_4-1" class="reference"><a href="#cite_note-chemgapedia-4">&#91;4&#93;</a></sup> 1956 treffen sich Wissenschaftler und Studenten auf der <a href="/wiki/Dartmouth_Conference" title="Dartmouth Conference">Dartmouth Conference</a>. Von 1957 bis 1958 entwickeln <a href="/wiki/Frank_Rosenblatt" title="Frank Rosenblatt">Frank Rosenblatt</a> und <a href="/w/index.php?title=Charles_Wightman&amp;action=edit&amp;redlink=1" class="new" title="Charles Wightman (Seite nicht vorhanden)">Charles Wightman</a> den ersten erfolgreichen Neurocomputer, mit dem Namen <i><a href="/w/index.php?title=Mark_I_Perceptron&amp;action=edit&amp;redlink=1" class="new" title="Mark I Perceptron (Seite nicht vorhanden)">Mark I Perceptron</a></i>. Der Computer konnte mit seinem 20 × 20 Pixel großen Bildsensor bereits einfache Ziffern erkennen. Im nachfolgenden Jahr formuliert Rosenblatt das <a href="/wiki/Perceptron-Konvergenz-Theorem" class="mw-redirect" title="Perceptron-Konvergenz-Theorem">Perceptron-Konvergenz-Theorem</a>. 1960 stellen <a href="/wiki/Bernard_Widrow" title="Bernard Widrow">Bernard Widrow</a> und <a href="/wiki/Marcian_E._Hoff" class="mw-redirect" title="Marcian E. Hoff">Marcian E. Hoff</a> das <i><a href="/wiki/ADALINE" class="mw-redirect" title="ADALINE">ADALINE</a></i> (<i>ADAptive LInear NEuron</i>) vor.<sup id="cite_ref-5" class="reference"><a href="#cite_note-5">&#91;5&#93;</a></sup> Dieses Netz erreichte als erstes weite kommerzielle Verbreitung. Anwendung fand es in Analogtelefonen zur Echtzeit-Echofilterung. Das Neuronale Netz lernte mit der <a href="/wiki/Deltaregel" class="mw-redirect" title="Deltaregel">Deltaregel</a>. 1961 stellte <a href="/wiki/Karl_Steinbuch" title="Karl Steinbuch">Karl Steinbuch</a> Techniken der assoziativen Speicherung vor. 1969 gaben Marvin Minsky und <a href="/wiki/Seymour_Papert" title="Seymour Papert">Seymour Papert</a> eine genaue mathematische Analyse des <a href="/wiki/Perceptron" class="mw-redirect" title="Perceptron">Perceptrons</a>.<sup id="cite_ref-6" class="reference"><a href="#cite_note-6">&#91;6&#93;</a></sup> Sie zeigten auf, dass wichtige Probleme nicht gelöst werden können. So sind unter anderem <a href="/wiki/Kontravalenz" title="Kontravalenz">XOR-Operatoren</a> nicht auflösbar und es gibt Probleme in der <a href="/wiki/Lineare_Separierbarkeit" title="Lineare Separierbarkeit">linearen Separierbarkeit</a>. Die Folge war ein vorläufiges Ende der Forschungen auf dem Gebiet der Neuronalen Netze, da die meisten Forschungsgelder gestrichen wurden.
</p>
<h3><span class="mw-headline" id="Langsamer_Wiederaufbau">Langsamer Wiederaufbau</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;veaction=edit&amp;section=5" class="mw-editsection-visualeditor" title="Abschnitt bearbeiten: Langsamer Wiederaufbau">Bearbeiten</a><span class="mw-editsection-divider"> | </span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;action=edit&amp;section=5" title="Abschnitt bearbeiten: Langsamer Wiederaufbau">Quelltext bearbeiten</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>1972 präsentiert <a href="/wiki/Teuvo_Kohonen" title="Teuvo Kohonen">Teuvo Kohonen</a> den <a href="/w/index.php?title=Linearer_Assoziator&amp;action=edit&amp;redlink=1" class="new" title="Linearer Assoziator (Seite nicht vorhanden)">linearen Assoziator</a>, ein Modell des Assoziativspeichers.<sup id="cite_ref-7" class="reference"><a href="#cite_note-7">&#91;7&#93;</a></sup> <a href="/w/index.php?title=James_A._Anderson&amp;action=edit&amp;redlink=1" class="new" title="James A. Anderson (Seite nicht vorhanden)">James A. Anderson</a> beschreibt das Modell unabhängig von Kohonen aus neuropsychologischer Sicht im selben Jahr.<sup id="cite_ref-8" class="reference"><a href="#cite_note-8">&#91;8&#93;</a></sup> 1973 benutzt <a href="/wiki/Christoph_von_der_Malsburg" title="Christoph von der Malsburg">Christoph von der Malsburg</a> ein <a href="/wiki/Neuronenmodell" title="Neuronenmodell">Neuronenmodell</a>, das nichtlinear ist. Bereits 1974 entwickelt <a href="/wiki/Paul_Werbos" title="Paul Werbos">Paul Werbos</a> für seine Dissertation die <a href="/wiki/Backpropagation" title="Backpropagation">Backpropagation</a> bzw. die Fehlerrückführung. Das Modell bekam aber erst später eine größere Bedeutung. Ab 1976 entwickelt <a href="/wiki/Stephen_Grossberg" title="Stephen Grossberg">Stephen Grossberg</a> mathematisch fundierte Modelle neuronaler Netze. Zusammen mit <a href="/w/index.php?title=Gail_Carpenter&amp;action=edit&amp;redlink=1" class="new" title="Gail Carpenter (Seite nicht vorhanden)">Gail Carpenter</a> widmet er sich auch dem Problem, ein neuronales Netz lernfähig zu halten, ohne bereits Gelerntes zu zerstören. Sie formulieren ein Architekturkonzept für Neuronale Netze, die <a href="/wiki/Adaptive_Resonanztheorie" title="Adaptive Resonanztheorie">Adaptive Resonanztheorie</a>. 1982 beschreibt Teuvo Kohonen die nach ihm benannten <a href="/wiki/Selbstorganisierende_Karte" title="Selbstorganisierende Karte">selbstorganisierenden Karten</a>. Im selben Jahr beschreibt <a href="/wiki/John_Hopfield" title="John Hopfield">John Hopfield</a> das Modell der <a href="/wiki/Hopfield-Netz" title="Hopfield-Netz">Hopfield-Netze</a>. 1983 wird von <a href="/w/index.php?title=Kunihiko_Fukushima&amp;action=edit&amp;redlink=1" class="new" title="Kunihiko Fukushima (Seite nicht vorhanden)">Kunihiko Fukushima</a>, S. Miyake und T. Ito das neuronale Modell <a href="/wiki/Neocognitron" title="Neocognitron">Neocognitron</a> vorgestellt. Das Modell ist eine Weiterentwicklung des 1975 entwickelten <a href="/w/index.php?title=Cognitron&amp;action=edit&amp;redlink=1" class="new" title="Cognitron (Seite nicht vorhanden)">Cognitrons</a> und dient zur Erkennung handgeschriebener Zeichen.
</p>
<h3><span class="mw-headline" id="Renaissance">Renaissance</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;veaction=edit&amp;section=6" class="mw-editsection-visualeditor" title="Abschnitt bearbeiten: Renaissance">Bearbeiten</a><span class="mw-editsection-divider"> | </span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;action=edit&amp;section=6" title="Abschnitt bearbeiten: Renaissance">Quelltext bearbeiten</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>1985 veröffentlicht <a href="/wiki/John_Hopfield" title="John Hopfield">John Hopfield</a> eine Lösung des <a href="/wiki/Travelling_Salesman_Problem" class="mw-redirect" title="Travelling Salesman Problem">Travelling Salesman Problems</a> durch ein <a href="/wiki/Hopfield-Netz" title="Hopfield-Netz">Hopfield-Netz</a>. 1985 wird das Lernverfahren <i><a href="/wiki/Backpropagation" title="Backpropagation">Backpropagation</a> of Error</i> als Verallgemeinerung der <a href="/wiki/Delta-Regel" class="mw-redirect" title="Delta-Regel">Delta-Regel</a> durch die <a href="/wiki/Parallel_Distributed_Processing" title="Parallel Distributed Processing">Parallel-Distributed-Processing</a>-Gruppe separat entwickelt. Somit werden nicht <a href="/wiki/Lineare_Separierbarkeit" title="Lineare Separierbarkeit">linear separierbare Probleme</a> durch mehrschichtige <a href="/wiki/Perceptron" class="mw-redirect" title="Perceptron">Perceptrons</a> lösbar. <a href="/wiki/Marvin_Minsky" title="Marvin Minsky">Minskys</a> Abschätzung war also widerlegt.
</p>
<h3><span class="mw-headline" id="Neue_Erfolge_in_Mustererkennungswettbewerben_seit_2009">Neue Erfolge in Mustererkennungswettbewerben seit 2009</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;veaction=edit&amp;section=7" class="mw-editsection-visualeditor" title="Abschnitt bearbeiten: Neue Erfolge in Mustererkennungswettbewerben seit 2009">Bearbeiten</a><span class="mw-editsection-divider"> | </span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;action=edit&amp;section=7" title="Abschnitt bearbeiten: Neue Erfolge in Mustererkennungswettbewerben seit 2009">Quelltext bearbeiten</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>In jüngster Zeit erlebten neuronale Netzwerke eine Wiedergeburt, da sie bei herausfordernden Anwendungen oft bessere Ergebnisse als konkurrierende Lernverfahren liefern. Zwischen 2009 und 2012 gewannen die <a href="/wiki/Rekurrentes_neuronales_Netz" title="Rekurrentes neuronales Netz">rekurrenten</a> bzw. tiefen vorwärtsgerichteten neuronalen Netzwerke der Forschungsgruppe von <a href="/wiki/J%C3%BCrgen_Schmidhuber" title="Jürgen Schmidhuber">Jürgen Schmidhuber</a> am <a href="/wiki/IDSIA" class="mw-redirect" title="IDSIA">Schweizer KI Labor IDSIA</a> eine Serie von acht internationalen Wettbewerben in den Bereichen <a href="/wiki/Mustererkennung" title="Mustererkennung">Mustererkennung</a> und <a href="/wiki/Maschinelles_Lernen" title="Maschinelles Lernen">maschinelles Lernen</a>.<sup id="cite_ref-9" class="reference"><a href="#cite_note-9">&#91;9&#93;</a></sup> Insbesondere gewannen ihre rekurrenten <a href="/wiki/Long_short-term_memory" title="Long short-term memory">LSTM-Netzwerke</a><sup id="cite_ref-10" class="reference"><a href="#cite_note-10">&#91;10&#93;</a></sup><sup id="cite_ref-11" class="reference"><a href="#cite_note-11">&#91;11&#93;</a></sup> drei Wettbewerbe zur verbundenen Handschrifterkennung bei der <i>2009 Intl. Conf. on Document Analysis and Recognition (ICDAR)</i> ohne eingebautes A-priori-Wissen über die drei verschiedenen zu lernenden Sprachen. Die LSTM-Netze erlernten gleichzeitige Segmentierung und Erkennung. Dies waren die ersten internationalen Wettbewerbe, die durch <i>Deep Learning</i><sup id="cite_ref-12" class="reference"><a href="#cite_note-12">&#91;12&#93;</a></sup><sup id="cite_ref-timeline_13-0" class="reference"><a href="#cite_note-timeline-13">&#91;13&#93;</a></sup> oder durch rekurrente Netze gewonnen wurden.
</p><p>Tiefe vorwärtsgerichtete Netzwerke wie Kunihiko Fukushimas <a href="/wiki/Convolutional_Neural_Network" title="Convolutional Neural Network">Konvolutionsnetz</a> der 80er Jahre<sup id="cite_ref-K._Fukushima._Neocognitron_1980_14-0" class="reference"><a href="#cite_note-K._Fukushima._Neocognitron_1980-14">&#91;14&#93;</a></sup> sind heute wieder wichtig. Sie verfügen über alternierende <a href="/wiki/Konvolution" class="mw-redirect" title="Konvolution">Konvolutionslagen</a> (<i>convolutional layers</i>) und Lagen von Neuronen, die mehrere Aktivierungen zusammenfassen (<i>pooling layers</i>), um die räumliche <a href="/wiki/Dimension_(Mathematik)" title="Dimension (Mathematik)">Dimension</a> zu reduzieren. Abgeschlossen wird ein solches Konvolutionsnetz in der Regel durch mehrere vollständig verbundene Lagen, sogenannte <i>fully connected layers</i>. <a href="/wiki/Yann_LeCun" title="Yann LeCun">Yann LeCuns</a> Team von der <a href="/wiki/New_York_University" title="New York University">New York University</a> wandte den 1989 schon gut bekannten <a href="/wiki/Backpropagation" title="Backpropagation">Backpropagation</a>-Algorithmus auf solche Netze an.<sup id="cite_ref-LeCun1989_15-0" class="reference"><a href="#cite_note-LeCun1989-15">&#91;15&#93;</a></sup> Moderne Varianten verwenden sogenanntes <i>max-pooling</i> für die Zusammenfassung der Aktivierungen, das stets der stärksten Aktivierung den Vorzug gibt.<sup id="cite_ref-M_Riesenhuber,_1999_16-0" class="reference"><a href="#cite_note-M_Riesenhuber,_1999-16">&#91;16&#93;</a></sup> Schnelle <a href="/wiki/Grafikprozessor" title="Grafikprozessor">GPU</a>-Implementierungen dieser Kombination wurden 2011 durch Dan Ciresan und Kollegen in Schmidhubers Gruppe eingeführt.<sup id="cite_ref-ciresan2011_17-0" class="reference"><a href="#cite_note-ciresan2011-17">&#91;17&#93;</a></sup> Sie gewannen seither zahlreiche Wettbewerbe, u.&#160;a. die „ISBI 2012 Segmentation of Neuronal Structures in Electron Microscopy Stacks Challenge“<sup id="cite_ref-D._Ciresan,_A._Giusti_2012_18-0" class="reference"><a href="#cite_note-D._Ciresan,_A._Giusti_2012-18">&#91;18&#93;</a></sup> und den „ICPR 2012 Contest on Mitosis Detection in Breast Cancer Histological Images“.<sup id="cite_ref-D._Ciresan,_A._Giusti_2013_19-0" class="reference"><a href="#cite_note-D._Ciresan,_A._Giusti_2013-19">&#91;19&#93;</a></sup> Derartige Modelle erzielten auch die bisher besten Ergebnisse auf dem <a href="/wiki/ImageNet" title="ImageNet">ImageNet</a> Benchmark.<sup id="cite_ref-Krizhevsky2012_20-0" class="reference"><a href="#cite_note-Krizhevsky2012-20">&#91;20&#93;</a></sup><sup id="cite_ref-Zeiler2013_21-0" class="reference"><a href="#cite_note-Zeiler2013-21">&#91;21&#93;</a></sup> GPU-basierte <i>max-pooling</i>-Konvolutionsnetze waren auch die ersten künstlichen Mustererkenner mit übermenschlicher Performanz<sup id="cite_ref-C._Ciresan,_U._Meier_2012_22-0" class="reference"><a href="#cite_note-C._Ciresan,_U._Meier_2012-22">&#91;22&#93;</a></sup> in Wettbewerben wie der „IJCNN 2011 Traffic Sign Recognition Competition“.<sup id="cite_ref-23" class="reference"><a href="#cite_note-23">&#91;23&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Topologie_der_Verbindungsnetzwerke">Topologie der Verbindungsnetzwerke</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;veaction=edit&amp;section=8" class="mw-editsection-visualeditor" title="Abschnitt bearbeiten: Topologie der Verbindungsnetzwerke">Bearbeiten</a><span class="mw-editsection-divider"> | </span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;action=edit&amp;section=8" title="Abschnitt bearbeiten: Topologie der Verbindungsnetzwerke">Quelltext bearbeiten</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="thumb tright"><div class="thumbinner" style="width:222px;"><a href="/wiki/Datei:SingleLayerNeuralNetwork_deutsch.png" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/b/b4/SingleLayerNeuralNetwork_deutsch.png/220px-SingleLayerNeuralNetwork_deutsch.png" decoding="async" width="220" height="197" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/b/b4/SingleLayerNeuralNetwork_deutsch.png/330px-SingleLayerNeuralNetwork_deutsch.png 1.5x, //upload.wikimedia.org/wikipedia/commons/b/b4/SingleLayerNeuralNetwork_deutsch.png 2x" data-file-width="387" data-file-height="347" /></a>  <div class="thumbcaption"><div class="magnify"><a href="/wiki/Datei:SingleLayerNeuralNetwork_deutsch.png" class="internal" title="vergrößern und Informationen zum Bild anzeigen"></a></div>Einschichtiges Netz</div></div></div>
<div class="thumb tright"><div class="thumbinner" style="width:222px;"><a href="/w/index.php?title=Datei:Multi-Layer_Neural_Network-Vector.svg&amp;lang=de" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/9/91/Multi-Layer_Neural_Network-Vector.svg/langde-220px-Multi-Layer_Neural_Network-Vector.svg.png" decoding="async" width="220" height="130" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/9/91/Multi-Layer_Neural_Network-Vector.svg/langde-330px-Multi-Layer_Neural_Network-Vector.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/9/91/Multi-Layer_Neural_Network-Vector.svg/langde-440px-Multi-Layer_Neural_Network-Vector.svg.png 2x" data-file-width="957" data-file-height="567" /></a>  <div class="thumbcaption"><div class="magnify"><a href="/wiki/Datei:Multi-Layer_Neural_Network-Vector.svg" class="internal" title="vergrößern und Informationen zum Bild anzeigen"></a></div>Zweischichtiges Netz</div></div></div>
<div class="thumb tright"><div class="thumbinner" style="width:222px;"><a href="/wiki/Datei:RecurrentLayerNeuralNetwork_deutsch.png" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/9/9e/RecurrentLayerNeuralNetwork_deutsch.png/220px-RecurrentLayerNeuralNetwork_deutsch.png" decoding="async" width="220" height="228" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/9/9e/RecurrentLayerNeuralNetwork_deutsch.png/330px-RecurrentLayerNeuralNetwork_deutsch.png 1.5x, //upload.wikimedia.org/wikipedia/commons/9/9e/RecurrentLayerNeuralNetwork_deutsch.png 2x" data-file-width="390" data-file-height="404" /></a>  <div class="thumbcaption"><div class="magnify"><a href="/wiki/Datei:RecurrentLayerNeuralNetwork_deutsch.png" class="internal" title="vergrößern und Informationen zum Bild anzeigen"></a></div>Rekurrentes Netz</div></div></div>
<p>In künstlichen neuronalen Netzen bezeichnet die Topologie die Struktur des Netzes. Damit ist im Allgemeinen gemeint, wie viele <a href="/wiki/K%C3%BCnstliches_Neuron" title="Künstliches Neuron">künstliche Neuronen</a> sich auf wie vielen Schichten befinden, und wie diese miteinander verbunden sind. Künstliche Neuronen können auf vielfältige Weise zu einem künstlichen neuronalen Netz verbunden werden. Dabei werden Neuronen bei vielen Modellen in hintereinander liegenden Schichten (<span style="font-style:normal;font-weight:normal"><a href="/wiki/Englische_Sprache" title="Englische Sprache">englisch</a></span> <span lang="en-Latn" style="font-style:italic">layers</span>) angeordnet; bei einem Netz mit nur einer trainierbaren Neuronenschicht spricht man von einem <i>einschichtigen Netz</i>.
</p><p>Unter Verwendung eines <a href="/wiki/Graph_(Graphentheorie)" title="Graph (Graphentheorie)">Graphen</a> können die Neuronen als <a href="/wiki/Knoten_(Graphentheorie)" title="Knoten (Graphentheorie)">Knoten</a> und ihre Verbindungen als <a href="/wiki/Kante_(Graphentheorie)" title="Kante (Graphentheorie)">Kanten</a> dargestellt werden. Die Eingaben werden gelegentlich auch als Knoten dargestellt.
</p><p>Die hinterste Schicht des Netzes, deren Neuronenausgaben meist als einzige außerhalb des Netzes sichtbar sind, wird <i>Ausgabeschicht</i> (englisch <i>output layer</i>) genannt. Davorliegende Schichten werden entsprechend als <i>verdeckte Schicht</i> (englisch <i>hidden layer</i>) bezeichnet.
</p>
<h3><span class="mw-headline" id="Typische_Strukturen">Typische Strukturen</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;veaction=edit&amp;section=9" class="mw-editsection-visualeditor" title="Abschnitt bearbeiten: Typische Strukturen">Bearbeiten</a><span class="mw-editsection-divider"> | </span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;action=edit&amp;section=9" title="Abschnitt bearbeiten: Typische Strukturen">Quelltext bearbeiten</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Die Struktur eines Netzwerks hängt unmittelbar mit dem verwendeten Lernverfahren zusammen und umgekehrt; so kann mit der <a href="/wiki/Delta-Regel" class="mw-redirect" title="Delta-Regel">Delta-Regel</a> nur ein einschichtiges Netz trainiert werden. Dabei müssen Netze nicht zwingend homogen sein: es existieren auch Kombinationen aus verschiedenen Modellen, um so unterschiedliche Vorteile zu kombinieren.
</p><p>Es gibt reine <i>feedforward</i>-Netze, bei denen eine Schicht immer nur mit der nächsthöheren Schicht verbunden ist. Darüber hinaus gibt es Netze, in denen Verbindungen in beiden Richtungen erlaubt sind. Die passende Netzstruktur wird meist nach der Methode von <a href="/wiki/Versuch_und_Irrtum" title="Versuch und Irrtum">Versuch und Irrtum</a> gefunden, was durch <a href="/wiki/Evolution%C3%A4rer_Algorithmus" title="Evolutionärer Algorithmus">evolutionäre Algorithmen</a> und eine <a href="/wiki/Backpropagation" title="Backpropagation">Fehlerrückführung</a> unterstützt werden kann.
</p>
<dl><dt>Einschichtiges feedforward-Netz</dt>
<dd>Einschichtige Netze mit der <i>feedforward</i>-Eigenschaft (englisch für <i>vorwärts</i>) sind die einfachsten Strukturen künstlicher neuronaler Netze. Sie besitzen lediglich eine Ausgabeschicht. Die <i>feedforward</i>-Eigenschaft besagt, dass Neuronenausgaben nur in Verarbeitungsrichtung geleitet werden und nicht durch eine rekurrente Kante zurückgeführt werden können (<a href="/wiki/Zyklus_(Graphentheorie)" title="Zyklus (Graphentheorie)">azyklischer</a>, <a href="/wiki/Gerichteter_Graph" title="Gerichteter Graph">gerichteter Graph</a>).</dd>
<dt>Mehrschichtiges feedforward-Netz</dt>
<dd>Mehrschichtige Netze besitzen neben der Ausgabeschicht auch verdeckte Schichten, deren Ausgabe wie beschrieben, außerhalb des Netzes nicht sichtbar sind. Verdeckte Schichten verbessern die Abstraktion solcher Netze. So kann erst das mehrschichtige <a href="/wiki/Perzeptron" title="Perzeptron">Perzeptron</a> das <a href="/wiki/XOR-Verkn%C3%BCpfung" class="mw-redirect" title="XOR-Verknüpfung">XOR</a>-Problem lösen.</dd>
<dt>Rekurrentes Netz</dt>
<dd><a href="/wiki/Rekurrentes_neuronales_Netz" title="Rekurrentes neuronales Netz">Rekurrente Netze</a> besitzen im Gegensatz dazu auch rückgerichtete (rekurrente) Kanten (englisch <i>feedback loops</i>) und enthalten somit eine <a href="/wiki/R%C3%BCckkopplung" title="Rückkopplung">Rückkopplung</a>. Solche Kanten werden dann häufig mit einer Zeitverzögerung versehen, sodass bei einer schrittweisen Verarbeitung die Neuronenausgaben der vergangenen Einheit wieder als Eingaben angelegt werden können. Diese Rückkopplungen ermöglichen einem Netz ein dynamisches Verhalten und statten es mit einem <a href="/wiki/Ged%C3%A4chtnis" title="Gedächtnis">Gedächtnis</a> aus.</dd></dl>
<p>In bestimmten Gehirnregionen von Säugetieren – und auch anderen Wirbeltieren, etwa Singvögeln – werden nicht nur in Entwicklungsstadien, sondern noch im Erwachsenenalter Neuronen neugebildet und in das neuronale Netzwerk integriert (siehe adulte <a href="/wiki/Neurogenese" title="Neurogenese">Neurogenese</a>, insbesondere <a href="/wiki/Hippocampus#Neurogenese_im_Hippocampus" title="Hippocampus">im Hippocampus</a>). Im Versuch, solche Prozesse in Neuronalen Netzen künstlich nachzubilden, stößt die Modellierung an Grenzen. Zwar kann ein <a href="/wiki/Evolution%C3%A4rer_Algorithmus" title="Evolutionärer Algorithmus">evolutionärer Algorithmus</a> bestimmen, ähnlich einem <a href="/wiki/Zellul%C3%A4rer_Automat" title="Zellulärer Automat">Moore-Automaten</a>, wie häufig ein Neuron aktiviert werden muss, damit sich in der Umgebung neue Neuronen ausbilden. Jedoch muss hier zusätzlich auch festgelegt werden, wie die neuen Neuronen in das vorhandene Netz integriert werden sollen. Künstliche Neuronale Netze dieser Art müssen zwangsläufig darauf verzichten, in Schichten aufgebaut zu sein. Sie benötigen eine völlig freie Struktur für die bestenfalls der Raum, in dem sich die Neuronen befinden dürfen, begrenzt werden kann.
</p>
<h2><span class="mw-headline" id="Anwendung">Anwendung</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;veaction=edit&amp;section=10" class="mw-editsection-visualeditor" title="Abschnitt bearbeiten: Anwendung">Bearbeiten</a><span class="mw-editsection-divider"> | </span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;action=edit&amp;section=10" title="Abschnitt bearbeiten: Anwendung">Quelltext bearbeiten</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Seine besonderen Eigenschaften machen das KNN bei allen Anwendungen interessant, bei denen kein oder nur geringes <a href="/wiki/Explizites_Wissen" title="Explizites Wissen">explizites (systematisches) Wissen</a> über das zu lösende Problem vorliegt. Dies sind z.&#160;B. die <a href="/wiki/Texterkennung" title="Texterkennung">Texterkennung</a>, <a href="/wiki/Bildverstehen" class="mw-redirect" title="Bildverstehen">Bilderkennung</a> und <a href="/wiki/Gesichtserkennung" title="Gesichtserkennung">Gesichtserkennung</a>, bei denen einige Hunderttausend bis Millionen <a href="/wiki/Pixel" title="Pixel">Bildpunkte</a> in eine im Vergleich dazu geringe Anzahl von erlaubten Ergebnissen überführt werden müssen.
</p><p>Auch in der <a href="/wiki/Regelungstechnik" title="Regelungstechnik">Regelungstechnik</a> kommen KNN zum Einsatz, um herkömmliche <a href="/wiki/Regler" title="Regler">Regler</a> zu ersetzen oder ihnen <a href="/wiki/Sollwert" title="Sollwert">Sollwerte</a> vorzugeben, die das Netz aus einer selbst entwickelten <a href="/wiki/Prognose" title="Prognose">Prognose</a> über den <a href="/wiki/Prozess_(Technik)" title="Prozess (Technik)">Prozessverlauf</a> ermittelt hat. So können auch <a href="/wiki/Fuzzy-Regler" title="Fuzzy-Regler">Fuzzy</a>-Systeme durch eine bidirektionale Umwandlung in Neuronale Netze lernfähig gestaltet werden.
</p><p>Die Anwendungsmöglichkeiten sind aber nicht auf techniknahe Gebiete begrenzt: Bei der Vorhersage von Veränderungen in komplexen Systemen werden KNNs unterstützend hinzugezogen, z.&#160;B. zur Früherkennung sich abzeichnender <a href="/wiki/Tornado" title="Tornado">Tornados</a> oder aber auch zur Abschätzung der weiteren Entwicklung wirtschaftlicher Prozesse.
</p><p>Zu den Anwendungsgebieten von KNNs gehören:
</p>
<ul><li>Regelung und Analyse komplexer <a href="/wiki/Prozess_(Technik)" title="Prozess (Technik)">Prozesse</a></li>
<li><a href="/wiki/Fr%C3%BChwarnsystem" title="Frühwarnsystem">Frühwarnsysteme</a></li>
<li><a href="/wiki/Fehlererkennung" class="mw-redirect" title="Fehlererkennung">Fehlererkennung</a></li>
<li><a href="/wiki/Optimierung" class="mw-redirect" title="Optimierung">Optimierung</a></li>
<li><a href="/wiki/Zeitreihenanalyse" title="Zeitreihenanalyse">Zeitreihenanalyse</a> (Wetter, Aktien usw.)</li>
<li><a href="/wiki/Sprachsynthese" title="Sprachsynthese">Sprachsynthese</a></li>
<li><a href="/wiki/Klassifikation" title="Klassifikation">Klassifikation</a></li>
<li><a href="/wiki/Bildverarbeitung" title="Bildverarbeitung">Bildverarbeitung</a> und <a href="/wiki/Mustererkennung" title="Mustererkennung">Mustererkennung</a>
<ul><li><a href="/wiki/Schrifterkennung" class="mw-redirect" title="Schrifterkennung">Schrifterkennung</a> (<a href="/wiki/Texterkennung" title="Texterkennung">OCR</a>)</li>
<li><a href="/wiki/Spracherkennung" title="Spracherkennung">Spracherkennung</a></li>
<li><a href="/wiki/Data-Mining" title="Data-Mining">Data-Mining</a></li>
<li><a href="/wiki/Maschinen%C3%BCbersetzung" class="mw-redirect" title="Maschinenübersetzung">Maschinenübersetzung</a></li></ul></li>
<li><a href="/wiki/Informatik" title="Informatik">Informatik</a>: Bei <a href="/wiki/Robotik" title="Robotik">Robotik</a>, <a href="/wiki/Virtueller_Agent" title="Virtueller Agent">virtuellen Agenten</a> und <a href="/wiki/K%C3%BCnstliche_Intelligenz" title="Künstliche Intelligenz">KI</a>-Modulen in Spielen und Simulationen</li>
<li><a href="/wiki/Diagnose" title="Diagnose">Medizinische Diagnostik</a>, <a href="/wiki/Epidemiologie" title="Epidemiologie">Epidemiologie</a> und <a href="/wiki/Biometrie" title="Biometrie">Biometrie</a></li>
<li><a href="/wiki/Klangsynthese" title="Klangsynthese">Klangsynthese</a></li>
<li><a href="/wiki/Strukturgleichungsmodell" title="Strukturgleichungsmodell">Strukturgleichungsmodell</a> zum Modellieren von sozialen oder betriebswirtschaftlichen Zusammenhängen</li></ul>
<p>Trotz dieser sehr großen Spanne an Anwendungsgebieten gibt es Bereiche, die aufgrund der Natur von KNNs <b>nicht</b> abgedeckt werden. Im Folgenden werden einige – für KNNs zu komplexe – Beispiele genannt:<sup id="cite_ref-24" class="reference"><a href="#cite_note-24">&#91;24&#93;</a></sup>
</p>
<ul><li>Vorhersage von <a href="/wiki/Zufallszahl" title="Zufallszahl">Zufalls-</a> oder Pseudozufalls-Zahlen</li>
<li><a href="/wiki/Faktorisierung" title="Faktorisierung">Faktorisierung</a> von großen Zahlen</li>
<li>Bestimmung, ob eine große Zahl <a href="/wiki/Primzahl" title="Primzahl">prim</a> ist</li>
<li>Entschlüsseln von <a href="/wiki/Verschl%C3%BCsselung" title="Verschlüsselung">verschlüsselten</a> Texten</li></ul>
<h2><span class="mw-headline" id="Biologische_Motivation">Biologische Motivation</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;veaction=edit&amp;section=11" class="mw-editsection-visualeditor" title="Abschnitt bearbeiten: Biologische Motivation">Bearbeiten</a><span class="mw-editsection-divider"> | </span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;action=edit&amp;section=11" title="Abschnitt bearbeiten: Biologische Motivation">Quelltext bearbeiten</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Während das <a href="/wiki/Gehirn" title="Gehirn">Gehirn</a> zur massiven Parallelverarbeitung in der Lage ist, arbeiten die meisten heutigen Computersysteme nur sequentiell (bzw. partiell parallel eines Rechners). Es gibt jedoch auch erste Prototypen neuronaler Rechnerarchitekturen, sozusagen den neuronalen Chip, für die das Forschungsgebiet der künstlichen neuronalen Netze die theoretischen Grundlagen bereitstellt. Dabei werden die <a href="/wiki/Neurophysiologie" title="Neurophysiologie">physiologischen Vorgänge</a> im Gehirn jedoch nicht nachgebildet, sondern nur die Architektur der massiv parallelen Analog-Addierer in Silizium nachgebaut, was gegenüber einer Software-Emulation eine bessere Leistung verspricht.
</p>
<h2><span class="mw-headline" id="Klassen_und_Typen_von_KNN">Klassen und Typen von KNN</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;veaction=edit&amp;section=12" class="mw-editsection-visualeditor" title="Abschnitt bearbeiten: Klassen und Typen von KNN">Bearbeiten</a><span class="mw-editsection-divider"> | </span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;action=edit&amp;section=12" title="Abschnitt bearbeiten: Klassen und Typen von KNN">Quelltext bearbeiten</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Grundsätzlich unterscheiden sich die Klassen der Netze vorwiegend durch die unterschiedlichen Netztopologien und Verbindungsarten, so zum Beispiel einschichtige, mehrschichtige, Feedforward- oder Feedback-Netze.
</p>
<ul><li><a href="/wiki/McCulloch-Pitts-Netz" class="mw-redirect" title="McCulloch-Pitts-Netz">McCulloch-Pitts-Netze</a></li>
<li><a href="/wiki/Lernmatrix" title="Lernmatrix">Lernmatrix</a></li>
<li><a href="/wiki/Perzeptron" title="Perzeptron">Perzeptron</a>
<ul><li><a href="/wiki/Adaline-Modell" title="Adaline-Modell">Adaline-Modell</a></li>
<li><a href="/wiki/Convolutional_Neural_Network" title="Convolutional Neural Network">Convolutional Neural Network</a> (CNN)</li></ul></li>
<li><a href="/wiki/Self-Organizing_Maps" class="mw-redirect" title="Self-Organizing Maps">Self-Organizing Maps</a> (auch <a href="/wiki/Teuvo_Kohonen" title="Teuvo Kohonen">Kohonen</a>-Netze) (SOM)</li>
<li><a href="/wiki/Growing_Neural_Gas" title="Growing Neural Gas">Growing Neural Gas</a> (GNG)</li>
<li><a href="/wiki/Lernende_Vektorquantisierung" title="Lernende Vektorquantisierung">Lernende Vektorquantisierung</a> (LVQ)</li>
<li><a href="/wiki/Boltzmann-Maschine" title="Boltzmann-Maschine">Boltzmann-Maschine</a></li>
<li><a href="/wiki/Cascade_Correlation" title="Cascade Correlation">Cascade-Correlation</a>-Netze</li>
<li><a href="/w/index.php?title=Counterpropagation_Netz&amp;action=edit&amp;redlink=1" class="new" title="Counterpropagation Netz (Seite nicht vorhanden)">Counterpropagation Netze</a></li>
<li><a href="/w/index.php?title=Probabilistisches_neuronales_Netz&amp;action=edit&amp;redlink=1" class="new" title="Probabilistisches neuronales Netz (Seite nicht vorhanden)">Probabilistische neuronale Netze</a></li>
<li><a href="/wiki/Radiale_Basisfunktion" title="Radiale Basisfunktion">Radiale Basisfunktions</a>-Netze (RBF)</li>
<li><a href="/wiki/Adaptive_Resonanztheorie" title="Adaptive Resonanztheorie">Adaptive Resonanztheorie</a> (ART)</li>
<li><a href="/wiki/Neocognitron" title="Neocognitron">Neocognitron</a></li>
<li><a href="/w/index.php?title=Spiking_Neural_Network&amp;action=edit&amp;redlink=1" class="new" title="Spiking Neural Network (Seite nicht vorhanden)">Spiking Neural Networks</a> (SNN)
<ul><li><a href="/w/index.php?title=Pulscodiertes_Neuronales_Netz&amp;action=edit&amp;redlink=1" class="new" title="Pulscodiertes Neuronales Netz (Seite nicht vorhanden)">Pulscodierte neuronale Netze</a> (PCNN)</li></ul></li>
<li><a href="/wiki/Time_Delay_Neural_Network" title="Time Delay Neural Network">Time Delay Neural Networks</a> (TDNNs)</li>
<li><a href="/wiki/Rekurrentes_neuronales_Netz" title="Rekurrentes neuronales Netz">Rekurrente neuronale Netze</a> (RNNs)
<ul><li><a href="/wiki/Bidirektionaler_Assoziativspeicher" title="Bidirektionaler Assoziativspeicher">Bidirektionaler Assoziativspeicher</a> (BAM)
<ul><li><a href="/wiki/Hopfield-Netz" title="Hopfield-Netz">Hopfield-Netze</a></li></ul></li>
<li><a href="/wiki/Elman-Netz" title="Elman-Netz">Elman-Netze</a> (auch Simple recurrent network, SRN)</li>
<li><a href="/wiki/Jordan-Netz" title="Jordan-Netz">Jordan-Netze</a></li></ul></li>
<li><a href="/wiki/Oszillierendes_neuronales_Netzwerk" title="Oszillierendes neuronales Netzwerk">Oszillierendes neuronales Netz</a></li></ul>
<h2><span class="mw-headline" id="Aktivierungsfunktion">Aktivierungsfunktion</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;veaction=edit&amp;section=13" class="mw-editsection-visualeditor" title="Abschnitt bearbeiten: Aktivierungsfunktion">Bearbeiten</a><span class="mw-editsection-divider"> | </span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;action=edit&amp;section=13" title="Abschnitt bearbeiten: Aktivierungsfunktion">Quelltext bearbeiten</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="hauptartikel" role="navigation"><span class="hauptartikel-pfeil" title="siehe" role="presentation">→ </span><i><span class="hauptartikel-text">Hauptartikel</span>: <a href="/wiki/K%C3%BCnstliches_Neuron#Aktivierungsfunktionen" title="Künstliches Neuron">„Aktivierungsfunktionen“ im Artikel Künstliches Neuron</a></i></div>
<p>Jede verdeckte Schicht und die Ausgabeschicht verfügen über eine (eigene) Aktivierungsfunktion. Diese können linear oder nicht-linear sein. Nicht-lineare Aktivierungsfunktionen machen das Netzwerk besonders mächtig.<sup id="cite_ref-25" class="reference"><a href="#cite_note-25">&#91;25&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Lernverfahren">Lernverfahren</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;veaction=edit&amp;section=14" class="mw-editsection-visualeditor" title="Abschnitt bearbeiten: Lernverfahren">Bearbeiten</a><span class="mw-editsection-divider"> | </span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;action=edit&amp;section=14" title="Abschnitt bearbeiten: Lernverfahren">Quelltext bearbeiten</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Lernverfahren dienen dazu, ein neuronales Netz dazu zu bringen, für bestimmte Eingangsmuster zugehörige Ausgabemuster zu erzeugen. Dies geschieht grundsätzlich auf drei verschiedenen Wegen.
</p>
<h3><span id=".C3.9Cberwachtes_Lernen_.28supervised_learning.29"></span><span class="mw-headline" id="Überwachtes_Lernen_(supervised_learning)">Überwachtes Lernen (supervised learning)</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;veaction=edit&amp;section=15" class="mw-editsection-visualeditor" title="Abschnitt bearbeiten: Überwachtes Lernen (supervised learning)">Bearbeiten</a><span class="mw-editsection-divider"> | </span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;action=edit&amp;section=15" title="Abschnitt bearbeiten: Überwachtes Lernen (supervised learning)">Quelltext bearbeiten</a><span class="mw-editsection-bracket">]</span></span></h3>
<div class="hauptartikel" role="navigation"><span class="hauptartikel-pfeil" title="siehe" role="presentation">→ </span><i><span class="hauptartikel-text">Hauptartikel</span>: <a href="/wiki/%C3%9Cberwachtes_Lernen" title="Überwachtes Lernen">Überwachtes Lernen</a></i></div>
<p>Beim Überwachten Lernen wird dem KNN ein Eingangsmuster gegeben und die Ausgabe, die das Neuronale Netz in seinem aktuellen Zustand produziert, mit dem Wert verglichen, den es eigentlich ausgeben soll. Durch Vergleich von Soll- und Istausgabe kann auf die vorzunehmenden Änderungen der Netzkonfiguration geschlossen werden. Bei einlagigen Perzeptrons kann die <a href="/wiki/Perzeptron#Perzeptron-Lernregel" title="Perzeptron">Delta-Regel</a> (auch Perzeptron-Lernregel) angewendet werden. Mehrlagige Perzeptrons werden in der Regel mit <a href="/wiki/Backpropagation" title="Backpropagation">Backpropagation</a> trainiert, was eine Verallgemeinerung der Delta-Regel darstellt.
</p>
<h3><span id="Un.C3.BCberwachtes_Lernen_.28unsupervised_learning.29"></span><span class="mw-headline" id="Unüberwachtes_Lernen_(unsupervised_learning)">Unüberwachtes Lernen (unsupervised learning)</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;veaction=edit&amp;section=16" class="mw-editsection-visualeditor" title="Abschnitt bearbeiten: Unüberwachtes Lernen (unsupervised learning)">Bearbeiten</a><span class="mw-editsection-divider"> | </span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;action=edit&amp;section=16" title="Abschnitt bearbeiten: Unüberwachtes Lernen (unsupervised learning)">Quelltext bearbeiten</a><span class="mw-editsection-bracket">]</span></span></h3>
<div class="hauptartikel" role="navigation"><span class="hauptartikel-pfeil" title="siehe" role="presentation">→ </span><i><span class="hauptartikel-text">Hauptartikel</span>: <a href="/wiki/Un%C3%BCberwachtes_Lernen" title="Unüberwachtes Lernen">Unüberwachtes Lernen</a></i></div>
<p>Das Unüberwachte Lernen erfolgt ausschließlich durch Eingabe der zu lernenden Muster. Das Neuronale Netz verändert sich entsprechend den Eingabemustern von selbst. Hierbei gibt es folgende Lernregeln:
</p>
<ul><li><a href="/wiki/Adaptive_Resonanztheorie" title="Adaptive Resonanztheorie">Adaptive Resonanztheorie</a></li>
<li><a href="/wiki/Hebbsche_Lernregel" title="Hebbsche Lernregel">Hebbsche Lernregel</a></li></ul>
<h3><span id="Best.C3.A4rkendes_Lernen_.28reinforced_learning.29"></span><span class="mw-headline" id="Bestärkendes_Lernen_(reinforced_learning)">Bestärkendes Lernen (reinforced learning)</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;veaction=edit&amp;section=17" class="mw-editsection-visualeditor" title="Abschnitt bearbeiten: Bestärkendes Lernen (reinforced learning)">Bearbeiten</a><span class="mw-editsection-divider"> | </span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;action=edit&amp;section=17" title="Abschnitt bearbeiten: Bestärkendes Lernen (reinforced learning)">Quelltext bearbeiten</a><span class="mw-editsection-bracket">]</span></span></h3>
<div class="hauptartikel" role="navigation"><span class="hauptartikel-pfeil" title="siehe" role="presentation">→ </span><i><span class="hauptartikel-text">Hauptartikel</span>: <a href="/wiki/Best%C3%A4rkendes_Lernen" title="Bestärkendes Lernen">Bestärkendes Lernen</a></i></div>
<p>Es ist nicht immer möglich, zu jedem Eingabedatensatz den passenden Ausgabedatensatz zum Trainieren zur Verfügung zu haben. Zum Beispiel kann man einem Agenten, der sich in einer fremden Umgebung zurechtfinden muss – etwa einem Roboter auf dem Mars – nicht zu jedem Zeitpunkt sagen, welche Aktion jeweils die beste ist. Aber man kann dem Agenten eine Aufgabe stellen, die dieser selbstständig lösen soll. Nach einem Testlauf, der aus mehreren Zeitschritten besteht, kann der Agent bewertet werden. Aufgrund dieser Bewertung kann eine Agentenfunktion gelernt werden.
</p><p>Der Lernschritt kann durch eine Vielzahl von Techniken vollzogen werden. Unter anderem können hier auch künstliche neuronale Netze zum Einsatz kommen.
</p>
<h3><span class="mw-headline" id="Stochastisches_Lernen">Stochastisches Lernen</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;veaction=edit&amp;section=18" class="mw-editsection-visualeditor" title="Abschnitt bearbeiten: Stochastisches Lernen">Bearbeiten</a><span class="mw-editsection-divider"> | </span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;action=edit&amp;section=18" title="Abschnitt bearbeiten: Stochastisches Lernen">Quelltext bearbeiten</a><span class="mw-editsection-bracket">]</span></span></h3>
<div class="hauptartikel" role="navigation"><span class="hauptartikel-pfeil" title="siehe" role="presentation">→ </span><i><span class="hauptartikel-text">Hauptartikel</span>: <a href="/wiki/Stochastisches_Lernen" title="Stochastisches Lernen">Stochastisches Lernen</a></i></div>
<ul><li><a href="/wiki/Simulierte_Abk%C3%BChlung" class="mw-redirect" title="Simulierte Abkühlung">Simulierte Abkühlung</a> (<i>Simulated Annealing</i>)</li></ul>
<h2><span class="mw-headline" id="Allgemeine_Probleme">Allgemeine Probleme</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;veaction=edit&amp;section=19" class="mw-editsection-visualeditor" title="Abschnitt bearbeiten: Allgemeine Probleme">Bearbeiten</a><span class="mw-editsection-divider"> | </span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;action=edit&amp;section=19" title="Abschnitt bearbeiten: Allgemeine Probleme">Quelltext bearbeiten</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Die <i>Hauptnachteile</i> von KNN sind gegenwärtig:
</p>
<ol><li>Das Trainieren von KNN (im Terminus der Statistik: Das Schätzen der im Modell enthaltenen Parameter) führt in der Regel zu hochdimensionalen, nichtlinearen Optimierungsproblemen. Die prinzipielle Schwierigkeit bei der Lösung dieser Probleme besteht in der Praxis häufig darin, dass man nicht sicher sein kann, ob man das globale Optimum gefunden hat oder nur ein lokales. Obgleich in der Mathematik eine Fülle relativ schnell konvergierender lokaler Optimierungsverfahren entwickelt wurden (beispielsweise <a href="/wiki/Quasi-Newton-Verfahren" title="Quasi-Newton-Verfahren">Quasi-Newton-Verfahren</a>: BFGS, DFP usw.), finden auch diese selten optimale Lösungen. Eine zeitaufwändige Näherung an die globale Lösung erreicht man gegebenenfalls durch die vielfache Wiederholung der Optimierung mit immer neuen Startwerten.</li>
<li>Es müssen Trainingsdaten gesammelt oder manuell erzeugt werden. Dieser Vorgang kann sehr schwierig sein, da man verhindern muss, dass das Netz Eigenschaften der Muster lernt, die zwar auf dem Trainingsset mit dem Ergebnis in irgendeiner Weise korreliert sind, die aber in anderen Situationen nicht zur Entscheidung herangezogen werden können. Wenn beispielsweise die Helligkeit von Trainingsbildern bestimmte Muster aufweist, dann 'achtet' das Netz unter Umständen nicht mehr auf die gewünschten Eigenschaften, sondern klassifiziert die Daten nur noch aufgrund der Helligkeit.</li>
<li>Bei Anwendung einer <a href="/wiki/Heuristisch" class="mw-redirect" title="Heuristisch">heuristischen</a> Vorgehensweise bei der Netzspezifikation neigen KNN dazu, die Trainingsdaten einfach auswendig zu lernen, infolge <a href="/wiki/%C3%9Cbergeneralisierung" class="mw-redirect" title="Übergeneralisierung">Übergeneralisierung</a> bzw. <a href="/wiki/%C3%9Cberanpassung" title="Überanpassung">Überanpassung</a>, auch <i>Overfitting</i> genannt.<sup id="cite_ref-26" class="reference"><a href="#cite_note-26">&#91;26&#93;</a></sup> Wenn dies geschieht, können die Netze nicht mehr auf neue Daten verallgemeinern. Um eine Überanpassung zu vermeiden, muss die Netzarchitektur mit Bedacht gewählt werden. In ähnlicher Weise besteht diese Problematik auch bei vielen anderen statistischen Verfahren und wird als <i>bias-variance trade-off</i> bezeichnet. Verbesserte Verfahren setzen <a href="/wiki/Boosting" title="Boosting">Boosting</a>, <a href="/wiki/Support-Vector-Maschine" class="mw-redirect" title="Support-Vector-Maschine">Support-Vector-Maschinen</a> oder <a href="/wiki/Regularisierung" class="mw-disambig" title="Regularisierung">Regularisierung</a> ein, um diesem Problem zu begegnen.</li>
<li>Die Kodierung der Trainingsdaten muss problemangepasst und nach Möglichkeit redundanzfrei gewählt werden. In welcher Form die zu lernenden Daten dem Netz präsentiert werden, hat einen großen Einfluss auf die Lerngeschwindigkeit, sowie darauf, ob das Problem überhaupt von einem Netz gelernt werden kann. Gute Beispiele hierfür sind Sprachdaten, Musikdaten oder auch Texte. Das einfache Einspeisen von Zahlen, beispielsweise einer .Wav-Datei für Sprache, führt selten zu einem erfolgreichen Ergebnis. Je präziser das Problem allein durch die Vorverarbeitung und Kodierung gestellt wird, desto erfolgreicher kann ein KNN dieses verarbeiten.</li>
<li>Die <a href="/wiki/Voreinstellung" title="Voreinstellung">Vorbelegung</a> der Gewichte spielt eine wichtige Rolle. Als Beispiel sei ein 3-schichtiges Feed-Forward-Netz mit einem Eingabeneuron (plus ein <a href="/wiki/Bias_(Neuron)" class="mw-redirect" title="Bias (Neuron)">Bias-Neuron</a>) und einem Ausgabeneuron und einer verdeckten Schicht mit N Neuronen (plus ein Bias-Neuron) angenommen. Die Aktivierungsfunktion des Eingabeneurons sei die Identität. Die Aktivierungsfunktion der verdeckten Schicht sei die Tanh-Funktion. Die Aktivierungsfunktion der Ausgabeschicht sei die logistische Sigmoide. Das Netz kann maximal eine Sinusfunktion mit N lokalen Extrema im Intervall von 0 bis 1 lernen. Wenn es diese Sinusfunktion gelernt hat, kann es mit dieser Gewichtsbelegung jede beliebige Funktion – die nicht mehr lokale Extrema als diese Sinusfunktion – mit möglicherweise exponentieller Beschleunigung – lernen (unabhängig vom Lernalgorithmus). Hier sei der einfachste Backpropagation ohne Momentum verwendet. Glücklicherweise kann man die Gewichte für solch eine Sinusfunktion leicht berechnen, ohne dass das Netz das erst lernen muss: Verdeckte Schicht&#160;: <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle i=0\ldots N-1}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>i</mi>
        <mo>=</mo>
        <mn>0</mn>
        <mo>&#x2026;<!-- … --></mo>
        <mi>N</mi>
        <mo>&#x2212;<!-- − --></mo>
        <mn>1</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle i=0\ldots N-1}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/cb3fb2767796963563fe8ff3a937ae754df9d141" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.505ex; width:14.627ex; height:2.343ex;" alt="{\displaystyle i=0\ldots N-1}"/></span>, x = i&#160;% 2 == 0&#160;? 1&#160;: -1 , <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle w_{0i}=x\cdot \pi \cdot (N-0{,}5),w_{li}=-x\cdot i\cdot \pi }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>w</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>=</mo>
        <mi>x</mi>
        <mo>&#x22C5;<!-- ⋅ --></mo>
        <mi>&#x03C0;<!-- π --></mi>
        <mo>&#x22C5;<!-- ⋅ --></mo>
        <mo stretchy="false">(</mo>
        <mi>N</mi>
        <mo>&#x2212;<!-- − --></mo>
        <mn>0</mn>
        <mrow class="MJX-TeXAtom-ORD">
          <mo>,</mo>
        </mrow>
        <mn>5</mn>
        <mo stretchy="false">)</mo>
        <mo>,</mo>
        <msub>
          <mi>w</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>l</mi>
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>=</mo>
        <mo>&#x2212;<!-- − --></mo>
        <mi>x</mi>
        <mo>&#x22C5;<!-- ⋅ --></mo>
        <mi>i</mi>
        <mo>&#x22C5;<!-- ⋅ --></mo>
        <mi>&#x03C0;<!-- π --></mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle w_{0i}=x\cdot \pi \cdot (N-0{,}5),w_{li}=-x\cdot i\cdot \pi }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c944181329a412f7bdeb3e8f03f0cc9c08fbd0b7" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:37.806ex; height:2.843ex;" alt="{\displaystyle w_{0i}=x\cdot \pi \cdot (N-0{,}5),w_{li}=-x\cdot i\cdot \pi }"/></span>; Ausgabeschicht&#160;: <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle w_{j}=1}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>w</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>j</mi>
          </mrow>
        </msub>
        <mo>=</mo>
        <mn>1</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle w_{j}=1}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6cd4009cc5de1a7fb80dfff161cabc206660d1e2" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:6.835ex; height:2.843ex;" alt="{\displaystyle w_{j}=1}"/></span>.</li></ol>
<h2><span class="mw-headline" id="Filmische_Dokumentationen">Filmische Dokumentationen</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;veaction=edit&amp;section=20" class="mw-editsection-visualeditor" title="Abschnitt bearbeiten: Filmische Dokumentationen">Bearbeiten</a><span class="mw-editsection-divider"> | </span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;action=edit&amp;section=20" title="Abschnitt bearbeiten: Filmische Dokumentationen">Quelltext bearbeiten</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><a rel="nofollow" class="external text" href="https://www.youtube.com/watch?v=o3RDCSJH2oo">Künstliche neuronale Netze - Computer lernen sehen, einfache Erklärung, 2017</a></li>
<li><a rel="nofollow" class="external text" href="https://www.youtube.com/watch?v=ILsA4nyG7I0">Künstliche neuronale Netze, komplexere Erklärung</a></li>
<li><a rel="nofollow" class="external text" href="https://www.youtube.com/watch?v=UF49iHT187o">Künstliche neuronale Netze - Programme lernen, einfache Erklärung, 2017</a></li></ul>
<h2><span class="mw-headline" id="Siehe_auch">Siehe auch</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;veaction=edit&amp;section=21" class="mw-editsection-visualeditor" title="Abschnitt bearbeiten: Siehe auch">Bearbeiten</a><span class="mw-editsection-divider"> | </span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;action=edit&amp;section=21" title="Abschnitt bearbeiten: Siehe auch">Quelltext bearbeiten</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><a href="/wiki/Aktivierungsraum" title="Aktivierungsraum">Aktivierungsraum</a></li>
<li><a href="/wiki/Maschinelles_Lernen" title="Maschinelles Lernen">Maschinelles Lernen</a></li>
<li><a href="/wiki/Neuronaler_Schaltkreis" title="Neuronaler Schaltkreis">Neuronaler Schaltkreis</a></li>
<li><a href="/wiki/Computational_Neuroscience" title="Computational Neuroscience">Computational Neuroscience</a></li>
<li><a href="/wiki/OpenNN" title="OpenNN">OpenNN</a></li></ul>
<h2><span class="mw-headline" id="Literatur">Literatur</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;veaction=edit&amp;section=22" class="mw-editsection-visualeditor" title="Abschnitt bearbeiten: Literatur">Bearbeiten</a><span class="mw-editsection-divider"> | </span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;action=edit&amp;section=22" title="Abschnitt bearbeiten: Literatur">Quelltext bearbeiten</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><a href="/wiki/Johann_Gasteiger" title="Johann Gasteiger">Johann Gasteiger</a>, Jure Zupan: <i>Neural Networks in Chemistry and Drug Design.</i> Wiley-VCH, Weinheim NY u. a. 1999, <a href="/wiki/Spezial:ISBN-Suche/3527297790" class="internal mw-magiclink-isbn">ISBN 3-527-29779-0</a>.</li>
<li>Simon Haykin: <i>Neural Networks. A Comprehensive Foundation.</i> 2. edition, international edition = Reprint. Prentice-Hall, Upper Saddle River NJ u. a. 1999, <a href="/wiki/Spezial:ISBN-Suche/0132733501" class="internal mw-magiclink-isbn">ISBN 0-13-273350-1</a>.</li>
<li>John Hertz, Anders Krogh, Richard G. Palmer: <i>Introduction to the Theory of Neural Computation.</i> Nachdruck. Addison-Wesley, Reading MA u. a. 1999, <a href="/wiki/Spezial:ISBN-Suche/0201515601" class="internal mw-magiclink-isbn">ISBN 0-201-51560-1</a> (<i>Santa Fé Institute studies in the sciences of complexity.</i> Lecture notes 1 = <i>Computation and neural systems series</i>).</li>
<li><a href="/wiki/Teuvo_Kohonen" title="Teuvo Kohonen">Teuvo Kohonen</a>: <i>Self Organizing Maps.</i> 3. edition. Springer, Berlin u. a. 2001, <a href="/wiki/Spezial:ISBN-Suche/3540679219" class="internal mw-magiclink-isbn">ISBN 3-540-67921-9</a> (<i>Springer Series in Information Sciences</i> 30 = <i>Physics and Astronomy online Library</i>).</li>
<li><a href="/wiki/Rudolf_Kruse" title="Rudolf Kruse">Rudolf Kruse</a>, Christian Borgelt, <a href="/wiki/Frank_Klawonn" title="Frank Klawonn">Frank Klawonn</a>, Christian Moewes, Georg Ruß, Matthias Steinbrecher: <i>Computational Intelligence.</i> 1. Auflage, Vieweg+Teubner Verlag/Springer Fachmedien Wiesbaden, 2011, <a href="/wiki/Spezial:ISBN-Suche/9783834812759" class="internal mw-magiclink-isbn">ISBN 978-3-8348-1275-9</a>.</li>
<li>Burkhard Lenze: <i>Einführung in die Mathematik neuronaler Netze. Mit C-Anwendungsprogrammen im Internet.</i> 3. durchgesehene und überarbeitete Auflage. Logos-Verlag, Berlin 2009, <a href="/wiki/Spezial:ISBN-Suche/3897220210" class="internal mw-magiclink-isbn">ISBN 3-89722-021-0</a>.</li>
<li>André Lucas: <i>Schätzung und Spezifikation ökonometrischer neuronaler Netze.</i> Eul, Lohmar 2003, <a href="/wiki/Spezial:ISBN-Suche/3899361830" class="internal mw-magiclink-isbn">ISBN 3-89936-183-0</a> (<i>Reihe: Quantitative Ökonomie</i> 138), (Zugleich: Köln, Univ., Diss., 2002).</li>
<li>Heinz Rehkugler, Hans Georg Zimmermann: <i>Neuronale Netze in der Ökonomie. Grundlagen und finanzwirtschaftliche Anwendungen.</i> Vahlen, München 1994, <a href="/wiki/Spezial:ISBN-Suche/3800618710" class="internal mw-magiclink-isbn">ISBN 3-800-61871-0</a>.</li>
<li>Günter Daniel Rey, Karl F. Wender: <i>Neuronale Netze. Eine Einführung in die Grundlagen, Anwendungen und Datenauswertung.</i> Hogrefe AG, Bern 2018, dritte Auflage, <a href="/wiki/Spezial:ISBN-Suche/9783456857961" class="internal mw-magiclink-isbn">ISBN 978-34568-5796-1</a> (<i>Psychologie Lehrbuch</i>).</li>
<li><a href="/wiki/Helge_Ritter" title="Helge Ritter">Helge Ritter</a>, <a href="/wiki/Thomas_Martinetz" title="Thomas Martinetz">Thomas Martinetz</a>, Klaus Schulten: <i>Neural Computation and Self-Organizing Maps. An Introduction.</i> Addison Wesley, Reading MA 1992, <a href="/wiki/Spezial:ISBN-Suche/0201554429" class="internal mw-magiclink-isbn">ISBN 0-201-55442-9</a> (<i>Computation and neural Systems Series</i>).</li>
<li><a href="/wiki/Ra%C3%BAl_Rojas" title="Raúl Rojas">Raúl Rojas</a>: <i>Theorie der Neuronalen Netze. Eine systematische Einführung.</i> 4. korrigierter Nachdruck. Springer, Berlin u. a. 1996, <a href="/wiki/Spezial:ISBN-Suche/3540563539" class="internal mw-magiclink-isbn">ISBN 3-540-56353-9</a> (<i>Springer-Lehrbuch</i>).</li>
<li>Andreas Zell: <i>Simulation neuronaler Netze.</i> 4. unveränderter Nachdruck. Oldenbourg, München u. a. 2003, <a href="/wiki/Spezial:ISBN-Suche/3486243500" class="internal mw-magiclink-isbn">ISBN 3-486-24350-0</a>.</li></ul>
<h2><span class="mw-headline" id="Weblinks">Weblinks</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;veaction=edit&amp;section=23" class="mw-editsection-visualeditor" title="Abschnitt bearbeiten: Weblinks">Bearbeiten</a><span class="mw-editsection-divider"> | </span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;action=edit&amp;section=23" title="Abschnitt bearbeiten: Weblinks">Quelltext bearbeiten</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="sisterproject" style="margin:0.1em 0 0 0;"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/4/4a/Commons-logo.svg/12px-Commons-logo.svg.png" decoding="async" title="Commons" width="12" height="16" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/4/4a/Commons-logo.svg/18px-Commons-logo.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/4/4a/Commons-logo.svg/24px-Commons-logo.svg.png 2x" data-file-width="1024" data-file-height="1376" />&#160;<b><span class="plainlinks"><a class="external text" href="https://commons.wikimedia.org/wiki/Artificial_neural_network?uselang=de">Commons: Künstliches neuronales Netz</a></span></b>&#160;– Album mit Bildern, Videos und Audiodateien</div>
<ul><li><a rel="nofollow" class="external text" href="http://www.neuronalesnetz.de/">Einführung in die Grundlagen und Anwendungen neuronaler Netze</a></li>
<li><a rel="nofollow" class="external text" href="http://www.dkriesel.com/science/neural_networks">Ein kleiner Überblick über Neuronale Netze</a> - Grundlagenskript zu zahlreichen Arten / Lernprinzipien Neuronaler Netze, viele Abbildungen, einfach geschrieben, ca. 200 Seiten (<a href="/wiki/PDF" class="mw-redirect" title="PDF">PDF</a>).</li>
<li><a rel="nofollow" class="external text" href="https://web.archive.org/web/20010515082546/http://wwwmath.uni-muenster.de/SoftComputing/lehre/material/wwwnnscript/startseite.html">Einführung in Neuronale Netze</a> (<a href="/wiki/Web-Archivierung#Begriffsbestimmung" title="Web-Archivierung">Memento</a>  vom 15. Mai 2001 im <i><a href="/wiki/Internet_Archive" title="Internet Archive">Internet Archive</a></i>)</li>
<li><a rel="nofollow" class="external text" href="http://www.neurocomputing.org/NNHistoryTo1960.aspx">Geschichte der Neuronalen Netze bis 1960</a> (englisch)</li>
<li><a rel="nofollow" class="external text" href="http://www.gc.ssr.upm.es/inves/neural/ann3/anntutorial.html">Tutorial zum Thema KNN</a></li>
<li><a rel="nofollow" class="external text" href="http://www.livescience.com/humanbiology/060327_neuro_chips.html"><i>Brain Cells Fused with Computer Chip</i></a></li>
<li><a rel="nofollow" class="external text" href="https://curlie.org/World/Deutsch/Wissenschaft/Informatik/Künstliche_Intelligenz/Neuronale_Netze/">Linkkatalog zum Thema Neuronale Netze</a> bei <i>curlie.org</i> (ehemals <a href="/wiki/DMOZ" title="DMOZ">DMOZ</a>)</li>
<li><a rel="nofollow" class="external text" href="http://www.ai-junkie.com/ann/evolved/nnt1.html">Gute Einführung in neuronale Netze</a> (englisch)</li></ul>
<h3><span class="mw-headline" id="Implementierungen_und_Simulationspakete">Implementierungen und Simulationspakete</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;veaction=edit&amp;section=24" class="mw-editsection-visualeditor" title="Abschnitt bearbeiten: Implementierungen und Simulationspakete">Bearbeiten</a><span class="mw-editsection-divider"> | </span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;action=edit&amp;section=24" title="Abschnitt bearbeiten: Implementierungen und Simulationspakete">Quelltext bearbeiten</a><span class="mw-editsection-bracket">]</span></span></h3>
<ul><li><a href="/wiki/TensorFlow" title="TensorFlow">TensorFlow</a> - Programmbibliothek</li>
<li><a href="/wiki/SNNS" class="mw-redirect" title="SNNS">SNNS</a> - Stuttgarter Neuronale-Netze-Simulator</li>
<li><a href="/wiki/EpsiloNN" title="EpsiloNN">EpsiloNN</a> neuronale Beschreibungssprache der <a href="/wiki/Universit%C3%A4t_Ulm" title="Universität Ulm">Universität Ulm</a></li></ul>
<h2><span class="mw-headline" id="Einzelnachweise">Einzelnachweise</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;veaction=edit&amp;section=25" class="mw-editsection-visualeditor" title="Abschnitt bearbeiten: Einzelnachweise">Bearbeiten</a><span class="mw-editsection-divider"> | </span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;action=edit&amp;section=25" title="Abschnitt bearbeiten: Einzelnachweise">Quelltext bearbeiten</a><span class="mw-editsection-bracket">]</span></span></h2>
<ol class="references">
<li id="cite_note-1"><span class="mw-cite-backlink"><a href="#cite_ref-1">↑</a></span> <span class="reference-text"><a rel="nofollow" class="external text" href="https://web.archive.org/web/20130502114900/http://www.math.rutgers.edu/~sontag/FTP_DIR/aml-turing.ps.gz">—</a> (<a href="/wiki/Web-Archivierung#Begriffsbestimmung" title="Web-Archivierung">Memento</a> des <span class="external text"><a class="external text" href="https://tools.wmflabs.org/giftbot/deref.fcgi?url=http%3A%2F%2Fwww.math.rutgers.edu%2F%7Esontag%2FFTP_DIR%2Faml-turing.ps.gz">Originals</a></span> vom 2. Mai 2013 im <i><a href="/wiki/Internet_Archive" title="Internet Archive">Internet Archive</a></i>)&#32;<small><span class="wp_boppel noviewer" role="presentation"><img alt="i" src="//upload.wikimedia.org/wikipedia/commons/thumb/4/4a/Pictogram_voting_info.svg/15px-Pictogram_voting_info.svg.png" decoding="async" title="i" width="15" height="15" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/4/4a/Pictogram_voting_info.svg/23px-Pictogram_voting_info.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/4/4a/Pictogram_voting_info.svg/30px-Pictogram_voting_info.svg.png 2x" data-file-width="250" data-file-height="250" /></span>&#160;<b>Info:</b> Der Archivlink wurde automatisch eingesetzt und noch nicht geprüft. Bitte prüfe Original- und Archivlink gemäß <a href="/wiki/Benutzer:InternetArchiveBot/Anleitung/Archivlink" title="Benutzer:InternetArchiveBot/Anleitung/Archivlink">Anleitung</a> und entferne dann diesen Hinweis.</small><span style="display:none"><a rel="nofollow" class="external text" href="http://IABotmemento.invalid/http://www.math.rutgers.edu/~sontag/FTP_DIR/aml-turing.ps.gz">@1</a></span><span style="display:none"><a rel="nofollow" class="external text" href="http://www.math.rutgers.edu/~sontag/FTP_DIR/aml-turing.ps.gz">@2</a></span><span style="display:none"><a href="/w/index.php?title=Vorlage:Webachiv/IABot/www.math.rutgers.edu&amp;action=edit&amp;redlink=1" class="new" title="Vorlage:Webachiv/IABot/www.math.rutgers.edu (Seite nicht vorhanden)">Vorlage:Webachiv/IABot/www.math.rutgers.edu</a></span></span>
</li>
<li id="cite_note-2"><span class="mw-cite-backlink"><a href="#cite_ref-2">↑</a></span> <span class="reference-text"><a rel="nofollow" class="external free" href="http://www.dkriesel.com/science/neural_networks">http://www.dkriesel.com/science/neural_networks</a>, Stand: 14. April 2016</span>
</li>
<li id="cite_note-3"><span class="mw-cite-backlink"><a href="#cite_ref-3">↑</a></span> <span class="reference-text">Warren S. McCulloch und Walter Pitts: <cite style="font-style:italic">A logical calculus of the ideas immanent in nervous activity</cite>. Hrsg.: Bulletin of Mathematical Biophysics. Vol. 5 Auflage. Kluwer Academic Publishers, 1943, <span style="white-space:nowrap">S.<span style="display:inline-block;width:.2em">&#160;</span>115&#8211;133</span>, <a href="/wiki/Digital_Object_Identifier" title="Digital Object Identifier">doi</a>:<span class="uri-handle"><a rel="nofollow" class="external text" href="//doi.org/10.1007/BF02478259">10.1007/BF02478259</a></span>.<span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rfr_id=info:sid/de.wikipedia.org:K%C3%BCnstliches+neuronales+Netz&amp;rft.au=Warren+S.+McCulloch+und+Walter+Pitts&amp;rft.btitle=A+logical+calculus+of+the+ideas+immanent+in+nervous+activity&amp;rft.date=1943&amp;rft.doi=10.1007%2FBF02478259&amp;rft.edition=Vol.+5&amp;rft.genre=book&amp;rft.pages=115-133&amp;rft.pub=Kluwer+Academic+Publishers" style="display:none">&#160;</span></span>
</li>
<li id="cite_note-chemgapedia-4"><span class="mw-cite-backlink">↑ <sup><a href="#cite_ref-chemgapedia_4-0">a</a></sup> <sup><a href="#cite_ref-chemgapedia_4-1">b</a></sup></span> <span class="reference-text"><span class="cite"><a rel="nofollow" class="external text" href="http://www.chemgapedia.de/vsengine/vlu/vsc/de/ch/13/vlu/daten/neuronalenetze/einfuehrung.vlu/Page/vsc/de/ch/13/anc/daten/neuronalenetze/snn1_6.vscml.html"><i>Neuronale Netze - Einführung.</i></a><span class="Abrufdatum">&#32;Abgerufen am 5.&#160;September 2015</span>&#32;(englisch).</span><span style="display: none;" class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adc&amp;rfr_id=info%3Asid%2Fde.wikipedia.org%3AK%C3%BCnstliches+neuronales+Netz&amp;rft.title=Neuronale+Netze+-+Einf%C3%BChrung&amp;rft.description=Neuronale+Netze+-+Einf%C3%BChrung&amp;rft.identifier=http%3A%2F%2Fwww.chemgapedia.de%2Fvsengine%2Fvlu%2Fvsc%2Fde%2Fch%2F13%2Fvlu%2Fdaten%2Fneuronalenetze%2Feinfuehrung.vlu%2FPage%2Fvsc%2Fde%2Fch%2F13%2Fanc%2Fdaten%2Fneuronalenetze%2Fsnn1_6.vscml.html&amp;rft.language=en">&#160;</span></span>
</li>
<li id="cite_note-5"><span class="mw-cite-backlink"><a href="#cite_ref-5">↑</a></span> <span class="reference-text">Bernhard Widrow, <a href="/wiki/Marcian_Hoff" class="mw-redirect" title="Marcian Hoff">Marcian Hoff</a>: <i>Adaptive switching circuits.</i> In: <i>Proceedings WESCON.</i> 1960, <span class="plainlinks-print"><a href="/wiki/Zeitschriftendatenbank" title="Zeitschriftendatenbank">ZDB</a>-ID&#32;<a rel="nofollow" class="external text" href="https://zdb-katalog.de/list.xhtml?t=267416-6&amp;key=zdb">267416-6</a></span>, S. 96–104.</span>
</li>
<li id="cite_note-6"><span class="mw-cite-backlink"><a href="#cite_ref-6">↑</a></span> <span class="reference-text"><a href="/wiki/Marvin_Minsky" title="Marvin Minsky">Marvin Minsky</a>, <a href="/wiki/Seymour_Papert" title="Seymour Papert">Seymour Papert</a>: <i>Perceptrons. An Introduction to Computational Geometry.</i> MIT Press, Cambridge MA u. a. 1969.</span>
</li>
<li id="cite_note-7"><span class="mw-cite-backlink"><a href="#cite_ref-7">↑</a></span> <span class="reference-text">Teuvo Kohonen: <i>Correlation matrix memories.</i> In: <i>IEEE transactions on computers.</i> C-21, 1972, <span class="plainlinks-print"><a href="/wiki/Internationale_Standardnummer_f%C3%BCr_fortlaufende_Sammelwerke" title="Internationale Standardnummer für fortlaufende Sammelwerke">ISSN</a>&#160;<a rel="nofollow" class="external text" href="https://zdb-katalog.de/list.xhtml?t=iss%3D%220018-9340%22&amp;key=cql">0018-9340</a></span>, S. 353–359.</span>
</li>
<li id="cite_note-8"><span class="mw-cite-backlink"><a href="#cite_ref-8">↑</a></span> <span class="reference-text">James A. Anderson: <i>A simple neural network generating an interactive memory.</i> In: <i>Mathematical Biosciences.</i> 14, 1972, <span class="plainlinks-print"><a href="/wiki/Internationale_Standardnummer_f%C3%BCr_fortlaufende_Sammelwerke" title="Internationale Standardnummer für fortlaufende Sammelwerke">ISSN</a>&#160;<a rel="nofollow" class="external text" href="https://zdb-katalog.de/list.xhtml?t=iss%3D%220025-5564%22&amp;key=cql">0025-5564</a></span>, S. 197–220.</span>
</li>
<li id="cite_note-9"><span class="mw-cite-backlink"><a href="#cite_ref-9">↑</a></span> <span class="reference-text"> <a rel="nofollow" class="external text" href="http://www.kurzweilai.net/how-bio-inspired-deep-learning-keeps-winning-competitions">2012 Kurzweil AI Interview</a> mit <a href="/wiki/J%C3%BCrgen_Schmidhuber" title="Jürgen Schmidhuber">Jürgen Schmidhuber</a> zu den acht Wettbewerben, die sein <a href="/wiki/Deep_Learning" title="Deep Learning">Deep Learning</a> Team zwischen 2009 und 2012 gewann</span>
</li>
<li id="cite_note-10"><span class="mw-cite-backlink"><a href="#cite_ref-10">↑</a></span> <span class="reference-text"> Alex Graves, Jürgen Schmidhuber: <i>Offline Handwriting Recognition with Multidimensional Recurrent Neural Networks.</i> In: Yoshua Bengio, Dale Schuurmans, John Lafferty, Chris K. I. Williams, Aron Culotta (Hrsg.): <i>Advances in Neural Information Processing Systems 22 (NIPS'22), December 7th–10th, 2009, Vancouver, BC.</i> Neural Information Processing Systems (NIPS) Foundation, 2009, S. 545–552</span>
</li>
<li id="cite_note-11"><span class="mw-cite-backlink"><a href="#cite_ref-11">↑</a></span> <span class="reference-text">A. Graves, M. Liwicki, S. Fernandez, R. Bertolami, H. Bunke, J. Schmidhuber: <i>A Novel Connectionist System for Improved Unconstrained Handwriting Recognition.</i> IEEE Transactions on Pattern Analysis and Machine Intelligence, Band 31, Nr. 5, 2009.</span>
</li>
<li id="cite_note-12"><span class="mw-cite-backlink"><a href="#cite_ref-12">↑</a></span> <span class="reference-text"> Y. Bengio: <a rel="nofollow" class="external text" href="http://www.iro.umontreal.ca/~bengioy/papers/ftml_book.pdf"><i>Learning Deep Architectures for AI.</i></a> Now Publishers, 2009.</span>
</li>
<li id="cite_note-timeline-13"><span class="mw-cite-backlink"><a href="#cite_ref-timeline_13-0">↑</a></span> <span class="reference-text"><a href="/wiki/J%C3%BCrgen_Schmidhuber" title="Jürgen Schmidhuber">Jürgen Schmidhuber</a>: <a rel="nofollow" class="external text" href="http://www.idsia.ch/~juergen/firstdeeplearner.html"><i>My First Deep Learning System of 1991 + Deep Learning Timeline 1962–2013.</i></a> </span>
</li>
<li id="cite_note-K._Fukushima._Neocognitron_1980-14"><span class="mw-cite-backlink"><a href="#cite_ref-K._Fukushima._Neocognitron_1980_14-0">↑</a></span> <span class="reference-text"><span id="Reference-K._Fukushima-1980">K. Fukushima:&#32;<cite>Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position</cite>.  In:  <cite>Biological Cybernetics</cite>.&#32;36, Nr.&#160;4,&#32; 1980, S.&#160;93–202. <a href="/wiki/Digital_Object_Identifier" title="Digital Object Identifier">doi</a>:<span class="uri-handle"><a rel="nofollow" class="external text" href="//doi.org/10.1007/BF00344251">10.1007/BF00344251</a></span>.</span> </span>
</li>
<li id="cite_note-LeCun1989-15"><span class="mw-cite-backlink"><a href="#cite_ref-LeCun1989_15-0">↑</a></span> <span class="reference-text">Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard, L. D. Jackel: <a rel="nofollow" class="external text" href="http://yann.lecun.com/exdb/publis/pdf/lecun-89e.pdf"><i>Backpropagation Applied to Handwritten Zip Code Recognition.</i></a> In: <i>Neural Computation.</i> Band 1, 1989. S. 541–551.</span>
</li>
<li id="cite_note-M_Riesenhuber,_1999-16"><span class="mw-cite-backlink"><a href="#cite_ref-M_Riesenhuber,_1999_16-0">↑</a></span> <span class="reference-text">M. Riesenhuber, T. Poggio: <a rel="nofollow" class="external text" href="http://riesenhuberlab.neuro.georgetown.edu/docs/publications/nn99.pdf"><i>Hierarchical models of object recognition in cortex.</i></a> In: <i>Nature Neuroscience.</i> 1999. </span>
</li>
<li id="cite_note-ciresan2011-17"><span class="mw-cite-backlink"><a href="#cite_ref-ciresan2011_17-0">↑</a></span> <span class="reference-text">D. C. Ciresan, U. Meier, J. Masci, L. M. Gambardella, J. Schmidhuber: <a rel="nofollow" class="external text" href="http://www.idsia.ch/~juergen/ijcai2011.pdf"><i>Flexible, High Performance Convolutional Neural Networks for Image Classification.</i></a> International Joint Conference on Artificial Intelligence (IJCAI-2011, Barcelona), 2011.</span>
</li>
<li id="cite_note-D._Ciresan,_A._Giusti_2012-18"><span class="mw-cite-backlink"><a href="#cite_ref-D._Ciresan,_A._Giusti_2012_18-0">↑</a></span> <span class="reference-text">D. Ciresan, A. Giusti, L. Gambardella, J. Schmidhuber: <a rel="nofollow" class="external text" href="http://www.idsia.ch/~juergen/nips2012.pdf"><i>Deep Neural Networks Segment Neuronal Membranes in Electron Microscopy Images.</i></a> In: <i>Advances in Neural Information Processing Systems</i> (NIPS 2012), Lake Tahoe, 2012. </span>
</li>
<li id="cite_note-D._Ciresan,_A._Giusti_2013-19"><span class="mw-cite-backlink"><a href="#cite_ref-D._Ciresan,_A._Giusti_2013_19-0">↑</a></span> <span class="reference-text">D. Ciresan, A. Giusti, L. Gambardella, J. Schmidhuber: <a rel="nofollow" class="external text" href="http://www.idsia.ch/~juergen/miccai2013.pdf"><i>Mitosis Detection in Breast Cancer Histology Images using Deep Neural Networks.</i></a> MICCAI 2013.</span>
</li>
<li id="cite_note-Krizhevsky2012-20"><span class="mw-cite-backlink"><a href="#cite_ref-Krizhevsky2012_20-0">↑</a></span> <span class="reference-text">A. Krizhevsky, I. Sutskever, G. E. Hinton: <a rel="nofollow" class="external text" href="http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf"><i>ImageNet Classification with Deep Convolutional Neural Networks.</i></a> NIPS 25, MIT Press, 2012.</span>
</li>
<li id="cite_note-Zeiler2013-21"><span class="mw-cite-backlink"><a href="#cite_ref-Zeiler2013_21-0">↑</a></span> <span class="reference-text">M. D. Zeiler, R. Fergus: <i>Visualizing and Understanding Convolutional Networks.</i> 2013. <a href="/wiki/ArXiv" title="ArXiv">arxiv</a>:<a rel="nofollow" class="external text" href="https://arxiv.org/abs/1311.2901">1311.2901</a></span>
</li>
<li id="cite_note-C._Ciresan,_U._Meier_2012-22"><span class="mw-cite-backlink"><a href="#cite_ref-C._Ciresan,_U._Meier_2012_22-0">↑</a></span> <span class="reference-text">D. C. Ciresan, U. Meier, <a href="/wiki/J%C3%BCrgen_Schmidhuber" title="Jürgen Schmidhuber">J. Schmidhuber</a>: <a rel="nofollow" class="external text" href="http://www.idsia.ch/~juergen/cvpr2012.pdf"><i>Multi-column Deep Neural Networks for Image Classification.</i></a> IEEE Conf. on Computer Vision and Pattern Recognition CVPR 2012.</span>
</li>
<li id="cite_note-23"><span class="mw-cite-backlink"><a href="#cite_ref-23">↑</a></span> <span class="reference-text">D. C. Ciresan, U. Meier, J. Masci, J. Schmidhuber: <a rel="nofollow" class="external text" href="http://www.idsia.ch/~juergen/nn2012traffic.pdf"><i>Multi-Column Deep Neural Network for Traffic Sign Classification.</i></a> Neural Networks, 2012. </span>
</li>
<li id="cite_note-24"><span class="mw-cite-backlink"><a href="#cite_ref-24">↑</a></span> <span class="reference-text"><span class="cite"><a rel="nofollow" class="external text" href="ftp://ftp.sas.com/pub/neural/FAQ.html#A_cando"><i>Neural Networks FAQ.</i></a><span class="Abrufdatum">&#32;Abgerufen am 5.&#160;September 2015</span>&#32;(englisch).</span><span style="display: none;" class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adc&amp;rfr_id=info%3Asid%2Fde.wikipedia.org%3AK%C3%BCnstliches+neuronales+Netz&amp;rft.title=Neural+Networks+FAQ&amp;rft.description=Neural+Networks+FAQ&amp;rft.identifier=ftp%3A%2F%2Fftp.sas.com%2Fpub%2Fneural%2FFAQ.html%23A_cando&amp;rft.language=en">&#160;</span></span>
</li>
<li id="cite_note-25"><span class="mw-cite-backlink"><a href="#cite_ref-25">↑</a></span> <span class="reference-text"><span class="cite"><a rel="nofollow" class="external text" href="ftp://ftp.sas.com/pub/neural/FAQ2.html#A_act"><i>Neural Networks FAQ.</i></a><span class="Abrufdatum">&#32;Abgerufen am 5.&#160;September 2015</span>&#32;(englisch).</span><span style="display: none;" class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adc&amp;rfr_id=info%3Asid%2Fde.wikipedia.org%3AK%C3%BCnstliches+neuronales+Netz&amp;rft.title=Neural+Networks+FAQ&amp;rft.description=Neural+Networks+FAQ&amp;rft.identifier=ftp%3A%2F%2Fftp.sas.com%2Fpub%2Fneural%2FFAQ2.html%23A_act&amp;rft.language=en">&#160;</span></span>
</li>
<li id="cite_note-26"><span class="mw-cite-backlink"><a href="#cite_ref-26">↑</a></span> <span class="reference-text"><span class="cite">Johannes Merkert:&#32;<a rel="nofollow" class="external text" href="https://www.heise.de/ct/ausgabe/2016-6-Ein-kuenstliches-neuronales-Netz-selbst-gebaut-3118857.html"><i>Ein künstliches neuronales Netz selbst gebaut.</i></a>&#32;In:&#32;<i>c't.</i><span class="Abrufdatum">&#32;Abgerufen am 24.&#160;Mai 2016</span>.</span><span style="display: none;" class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adc&amp;rfr_id=info%3Asid%2Fde.wikipedia.org%3AK%C3%BCnstliches+neuronales+Netz&amp;rft.title=Ein+k%C3%BCnstliches+neuronales+Netz+selbst+gebaut&amp;rft.description=Ein+k%C3%BCnstliches+neuronales+Netz+selbst+gebaut&amp;rft.identifier=https%3A%2F%2Fwww.heise.de%2Fct%2Fausgabe%2F2016-6-Ein-kuenstliches-neuronales-Netz-selbst-gebaut-3118857.html&amp;rft.creator=Johannes+Merkert">&#160;</span></span>
</li>
</ol>
<div id="normdaten" class="catlinks normdaten-typ-s">Normdaten&#160;(Sachbegriff): <a href="/wiki/Gemeinsame_Normdatei" title="Gemeinsame Normdatei">GND</a>: <span class="plainlinks-print"><a rel="nofollow" class="external text" href="https://d-nb.info/gnd/4226127-2">4226127-2</a></span> <span class="metadata noprint">(<a rel="nofollow" class="external text" href="https://beacon.findbuch.de/seemore/gnd-aks?format=sources&amp;id=4226127-2">AKS</a>)</span>       <span class="metadata"></span></div>
<!-- 
NewPP limit report
Parsed by mw1240
Cached time: 20190430152710
Cache expiry: 2592000
Dynamic content: false
CPU time usage: 0.692 seconds
Real time usage: 0.882 seconds
Preprocessor visited node count: 2633/1000000
Preprocessor generated node count: 0/1500000
Post‐expand include size: 25737/2097152 bytes
Template argument size: 5673/2097152 bytes
Highest expansion depth: 13/40
Expensive parser function count: 5/500
Unstrip recursion depth: 0/20
Unstrip post‐expand size: 17997/5000000 bytes
Number of Wikibase entities loaded: 1/400
Lua time usage: 0.211/10.000 seconds
Lua memory usage: 5.31 MB/50 MB
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  609.699      1 -total
 30.08%  183.378      4 Vorlage:Internetquelle
 15.15%   92.393      1 Vorlage:Cite_journal
 12.23%   74.569      1 Vorlage:Literatur
 10.72%   65.332      2 Vorlage:Webarchiv
  9.01%   54.931      1 Vorlage:Normdaten
  7.44%   45.376      1 Vorlage:EnS
  7.43%   45.282      1 Vorlage:Wikidata-Registrierung
  5.48%   33.420      2 Vorlage:FormatDate
  4.13%   25.191      4 Vorlage:Str_len
-->

<!-- Saved in parser cache with key dewiki:stable-pcache:idhash:26775-0!canonical!math=5 and timestamp 20190430152710 and revision id 187559803
 -->
</div><noscript><img src="//de.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" /></noscript></div>
		
		<div class="printfooter">Abgerufen von „<a dir="ltr" href="https://de.wikipedia.org/w/index.php?title=Künstliches_neuronales_Netz&amp;oldid=187559803">https://de.wikipedia.org/w/index.php?title=Künstliches_neuronales_Netz&amp;oldid=187559803</a>“</div>
		
		<div id="catlinks" class="catlinks" data-mw="interface"><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="/wiki/Wikipedia:Kategorien" title="Wikipedia:Kategorien">Kategorien</a>: <ul><li><a href="/wiki/Kategorie:Neuroinformatik" title="Kategorie:Neuroinformatik">Neuroinformatik</a></li><li><a href="/wiki/Kategorie:K%C3%BCnstliche_Neuronale_Netze" title="Kategorie:Künstliche Neuronale Netze">Künstliche Neuronale Netze</a></li><li><a href="/wiki/Kategorie:Regressionsanalyse" title="Kategorie:Regressionsanalyse">Regressionsanalyse</a></li><li><a href="/wiki/Kategorie:Klassifikationsverfahren" title="Kategorie:Klassifikationsverfahren">Klassifikationsverfahren</a></li></ul></div><div id="mw-hidden-catlinks" class="mw-hidden-catlinks mw-hidden-cats-hidden">Versteckte Kategorie: <ul><li><a href="/wiki/Kategorie:Wikipedia:Defekte_Weblinks/Ungepr%C3%BCfte_Archivlinks_2018-11" title="Kategorie:Wikipedia:Defekte Weblinks/Ungeprüfte Archivlinks 2018-11">Wikipedia:Defekte Weblinks/Ungeprüfte Archivlinks 2018-11</a></li></ul></div></div>
		
		<div class="visualClear"></div>
		
	</div>
</div>

		<div id="mw-navigation">
			<h2>Navigationsmenü</h2>
			<div id="mw-head">
									<div id="p-personal" role="navigation" aria-labelledby="p-personal-label">
						<h3 id="p-personal-label">Meine Werkzeuge</h3>
						<ul>
							<li id="pt-anonuserpage">Nicht angemeldet</li><li id="pt-anontalk"><a href="/wiki/Spezial:Meine_Diskussionsseite" title="Diskussion über Änderungen von dieser IP-Adresse [n]" accesskey="n">Diskussionsseite</a></li><li id="pt-anoncontribs"><a href="/wiki/Spezial:Meine_Beitr%C3%A4ge" title="Eine Liste der Bearbeitungen, die von dieser IP-Adresse gemacht wurden [y]" accesskey="y">Beiträge</a></li><li id="pt-createaccount"><a href="/w/index.php?title=Spezial:Benutzerkonto_anlegen&amp;returnto=K%C3%BCnstliches+neuronales+Netz" title="Wir ermutigen dich dazu, ein Benutzerkonto zu erstellen und dich anzumelden. Es ist jedoch nicht zwingend erforderlich.">Benutzerkonto erstellen</a></li><li id="pt-login"><a href="/w/index.php?title=Spezial:Anmelden&amp;returnto=K%C3%BCnstliches+neuronales+Netz" title="Anmelden ist zwar keine Pflicht, wird aber gerne gesehen. [o]" accesskey="o">Anmelden</a></li>						</ul>
					</div>
									<div id="left-navigation">
										<div id="p-namespaces" role="navigation" class="vectorTabs" aria-labelledby="p-namespaces-label">
						<h3 id="p-namespaces-label">Namensräume</h3>
						<ul>
							<li id="ca-nstab-main" class="selected"><span><a href="/wiki/K%C3%BCnstliches_neuronales_Netz" title="Seiteninhalt anzeigen [c]" accesskey="c">Artikel</a></span></li><li id="ca-talk"><span><a href="/wiki/Diskussion:K%C3%BCnstliches_neuronales_Netz" rel="discussion" title="Diskussion zum Seiteninhalt [t]" accesskey="t">Diskussion</a></span></li>						</ul>
					</div>
										<div id="p-variants" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-variants-label">
												<input type="checkbox" class="vectorMenuCheckbox" aria-labelledby="p-variants-label" />
						<h3 id="p-variants-label">
							<span>Varianten</span>
						</h3>
						<ul class="menu">
													</ul>
					</div>
									</div>
				<div id="right-navigation">
										<div id="p-views" role="navigation" class="vectorTabs" aria-labelledby="p-views-label">
						<h3 id="p-views-label">Ansichten</h3>
						<ul>
							<li id="ca-view" class="collapsible selected"><span><a href="/wiki/K%C3%BCnstliches_neuronales_Netz">Lesen</a></span></li><li id="ca-ve-edit" class="collapsible"><span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;veaction=edit" title="Diese Seite mit dem VisualEditor bearbeiten [v]" accesskey="v">Bearbeiten</a></span></li><li id="ca-edit" class="collapsible"><span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;action=edit" title="Diese Seite bearbeiten [e]" accesskey="e">Quelltext bearbeiten</a></span></li><li id="ca-history" class="collapsible"><span><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;action=history" title="Frühere Versionen dieser Seite [h]" accesskey="h">Versionsgeschichte</a></span></li>						</ul>
					</div>
										<div id="p-cactions" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-cactions-label">
						<input type="checkbox" class="vectorMenuCheckbox" aria-labelledby="p-cactions-label" />
						<h3 id="p-cactions-label"><span>Mehr</span></h3>
						<ul class="menu">
													</ul>
					</div>
										<div id="p-search" role="search">
						<h3>
							<label for="searchInput">Suche</label>
						</h3>
						<form action="/w/index.php" id="searchform">
							<div id="simpleSearch">
								<input type="search" name="search" placeholder="Wikipedia durchsuchen" title="Durchsuche die Wikipedia [f]" accesskey="f" id="searchInput"/><input type="hidden" value="Spezial:Suche" name="title"/><input type="submit" name="fulltext" value="Suchen" title="Suche nach Seiten, die diesen Text enthalten" id="mw-searchButton" class="searchButton mw-fallbackSearchButton"/><input type="submit" name="go" value="Artikel" title="Gehe direkt zu der Seite mit genau diesem Namen, falls sie vorhanden ist." id="searchButton" class="searchButton"/>							</div>
						</form>
					</div>
									</div>
			</div>
			<div id="mw-panel">
				<div id="p-logo" role="banner"><a class="mw-wiki-logo" href="/wiki/Wikipedia:Hauptseite" title="Hauptseite"></a></div>
						<div class="portal" role="navigation" id="p-navigation" aria-labelledby="p-navigation-label">
			<h3 id="p-navigation-label">Navigation</h3>
			<div class="body">
								<ul>
					<li id="n-mainpage-description"><a href="/wiki/Wikipedia:Hauptseite" title="Hauptseite besuchen [z]" accesskey="z">Hauptseite</a></li><li id="n-topics"><a href="/wiki/Portal:Wikipedia_nach_Themen">Themenportale</a></li><li id="n-randompage"><a href="/wiki/Spezial:Zuf%C3%A4llige_Seite" title="Zufällige Seite aufrufen [x]" accesskey="x">Zufälliger Artikel</a></li>				</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id="p-Mitmachen" aria-labelledby="p-Mitmachen-label">
			<h3 id="p-Mitmachen-label">Mitmachen</h3>
			<div class="body">
								<ul>
					<li id="n-Artikel-verbessern"><a href="/wiki/Wikipedia:Beteiligen">Artikel verbessern</a></li><li id="n-Neuerartikel"><a href="/wiki/Hilfe:Neuen_Artikel_anlegen">Neuen Artikel anlegen</a></li><li id="n-portal"><a href="/wiki/Wikipedia:Autorenportal" title="Info-Zentrum über Beteiligungsmöglichkeiten">Autorenportal</a></li><li id="n-help"><a href="/wiki/Hilfe:%C3%9Cbersicht" title="Hilfeseite anzeigen">Hilfe</a></li><li id="n-recentchanges"><a href="/wiki/Spezial:Letzte_%C3%84nderungen" title="Liste der letzten Änderungen in Wikipedia [r]" accesskey="r">Letzte Änderungen</a></li><li id="n-contact"><a href="/wiki/Wikipedia:Kontakt">Kontakt</a></li><li id="n-sitesupport"><a href="//donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_de.wikipedia.org&amp;uselang=de" title="Unterstütze uns">Spenden</a></li>				</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id="p-tb" aria-labelledby="p-tb-label">
			<h3 id="p-tb-label">Werkzeuge</h3>
			<div class="body">
								<ul>
					<li id="t-whatlinkshere"><a href="/wiki/Spezial:Linkliste/K%C3%BCnstliches_neuronales_Netz" title="Liste aller Seiten, die hierher verlinken [j]" accesskey="j">Links auf diese Seite</a></li><li id="t-recentchangeslinked"><a href="/wiki/Spezial:%C3%84nderungen_an_verlinkten_Seiten/K%C3%BCnstliches_neuronales_Netz" rel="nofollow" title="Letzte Änderungen an Seiten, die von hier verlinkt sind [k]" accesskey="k">Änderungen an verlinkten Seiten</a></li><li id="t-specialpages"><a href="/wiki/Spezial:Spezialseiten" title="Liste aller Spezialseiten [q]" accesskey="q">Spezialseiten</a></li><li id="t-permalink"><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;oldid=187559803" title="Dauerhafter Link zu dieser Seitenversion">Permanenter Link</a></li><li id="t-info"><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;action=info" title="Weitere Informationen über diese Seite">Seiten­informationen</a></li><li id="t-wikibase"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q192776" title="Link zum verbundenen Objekt im Datenrepositorium [g]" accesskey="g">Wikidata-Datenobjekt</a></li><li id="t-cite"><a href="/w/index.php?title=Spezial:Zitierhilfe&amp;page=K%C3%BCnstliches_neuronales_Netz&amp;id=187559803" title="Hinweise, wie diese Seite zitiert werden kann">Artikel zitieren</a></li>				</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id="p-coll-print_export" aria-labelledby="p-coll-print_export-label">
			<h3 id="p-coll-print_export-label">Drucken/­exportieren</h3>
			<div class="body">
								<ul>
					<li id="coll-create_a_book"><a href="/w/index.php?title=Spezial:Buch&amp;bookcmd=book_creator&amp;referer=K%C3%BCnstliches+neuronales+Netz">Buch erstellen</a></li><li id="coll-download-as-rdf2latex"><a href="/w/index.php?title=Spezial:ElectronPdf&amp;page=K%C3%BCnstliches+neuronales+Netz&amp;action=show-download-screen">Als PDF herunterladen</a></li><li id="t-print"><a href="/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;printable=yes" title="Druckansicht dieser Seite [p]" accesskey="p">Druckversion</a></li>				</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id="p-wikibase-otherprojects" aria-labelledby="p-wikibase-otherprojects-label">
			<h3 id="p-wikibase-otherprojects-label">In anderen Projekten</h3>
			<div class="body">
								<ul>
					<li class="wb-otherproject-link wb-otherproject-commons"><a href="https://commons.wikimedia.org/wiki/Category:Artificial_neural_network" hreflang="en">Commons</a></li>				</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id="p-lang" aria-labelledby="p-lang-label">
			<h3 id="p-lang-label">In anderen Sprachen</h3>
			<div class="body">
								<ul>
					<li class="interlanguage-link interwiki-ar"><a href="https://ar.wikipedia.org/wiki/%D8%B4%D8%A8%D9%83%D8%A9_%D8%B9%D8%B5%D8%A8%D9%88%D9%86%D9%8A%D8%A9_%D8%A7%D8%B5%D8%B7%D9%86%D8%A7%D8%B9%D9%8A%D8%A9" title="شبكة عصبونية اصطناعية – Arabisch" lang="ar" hreflang="ar" class="interlanguage-link-target">العربية</a></li><li class="interlanguage-link interwiki-az"><a href="https://az.wikipedia.org/wiki/S%C3%BCni_neyron_%C5%9F%C9%99b%C9%99k%C9%99l%C9%99r" title="Süni neyron şəbəkələr – Aserbaidschanisch" lang="az" hreflang="az" class="interlanguage-link-target">Azərbaycanca</a></li><li class="interlanguage-link interwiki-bg"><a href="https://bg.wikipedia.org/wiki/%D0%98%D0%B7%D0%BA%D1%83%D1%81%D1%82%D0%B2%D0%B5%D0%BD%D0%B0_%D0%BD%D0%B5%D0%B2%D1%80%D0%BE%D0%BD%D0%BD%D0%B0_%D0%BC%D1%80%D0%B5%D0%B6%D0%B0" title="Изкуствена невронна мрежа – Bulgarisch" lang="bg" hreflang="bg" class="interlanguage-link-target">Български</a></li><li class="interlanguage-link interwiki-bs"><a href="https://bs.wikipedia.org/wiki/Vje%C5%A1ta%C4%8Dka_neuronska_mre%C5%BEa" title="Vještačka neuronska mreža – Bosnisch" lang="bs" hreflang="bs" class="interlanguage-link-target">Bosanski</a></li><li class="interlanguage-link interwiki-ca"><a href="https://ca.wikipedia.org/wiki/Xarxa_neuronal_artificial" title="Xarxa neuronal artificial – Katalanisch" lang="ca" hreflang="ca" class="interlanguage-link-target">Català</a></li><li class="interlanguage-link interwiki-cs"><a href="https://cs.wikipedia.org/wiki/Um%C4%9Bl%C3%A1_neuronov%C3%A1_s%C3%AD%C5%A5" title="Umělá neuronová síť – Tschechisch" lang="cs" hreflang="cs" class="interlanguage-link-target">Čeština</a></li><li class="interlanguage-link interwiki-da"><a href="https://da.wikipedia.org/wiki/Kunstigt_neuralt_netv%C3%A6rk" title="Kunstigt neuralt netværk – Dänisch" lang="da" hreflang="da" class="interlanguage-link-target">Dansk</a></li><li class="interlanguage-link interwiki-el"><a href="https://el.wikipedia.org/wiki/%CE%9D%CE%B5%CF%85%CF%81%CF%89%CE%BD%CE%B9%CE%BA%CF%8C_%CE%B4%CE%AF%CE%BA%CF%84%CF%85%CE%BF" title="Νευρωνικό δίκτυο – Griechisch" lang="el" hreflang="el" class="interlanguage-link-target">Ελληνικά</a></li><li class="interlanguage-link interwiki-en"><a href="https://en.wikipedia.org/wiki/Artificial_neural_network" title="Artificial neural network – Englisch" lang="en" hreflang="en" class="interlanguage-link-target">English</a></li><li class="interlanguage-link interwiki-eo"><a href="https://eo.wikipedia.org/wiki/Artefarita_ne%C5%ADra_reto" title="Artefarita neŭra reto – Esperanto" lang="eo" hreflang="eo" class="interlanguage-link-target">Esperanto</a></li><li class="interlanguage-link interwiki-es"><a href="https://es.wikipedia.org/wiki/Red_neuronal_artificial" title="Red neuronal artificial – Spanisch" lang="es" hreflang="es" class="interlanguage-link-target">Español</a></li><li class="interlanguage-link interwiki-et"><a href="https://et.wikipedia.org/wiki/Tehisn%C3%A4rviv%C3%B5rk" title="Tehisnärvivõrk – Estnisch" lang="et" hreflang="et" class="interlanguage-link-target">Eesti</a></li><li class="interlanguage-link interwiki-eu"><a href="https://eu.wikipedia.org/wiki/Neurona-sare_artifizial" title="Neurona-sare artifizial – Baskisch" lang="eu" hreflang="eu" class="interlanguage-link-target">Euskara</a></li><li class="interlanguage-link interwiki-fa"><a href="https://fa.wikipedia.org/wiki/%D8%B4%D8%A8%DA%A9%D9%87_%D8%B9%D8%B5%D8%A8%DB%8C_%D9%85%D8%B5%D9%86%D9%88%D8%B9%DB%8C" title="شبکه عصبی مصنوعی – Persisch" lang="fa" hreflang="fa" class="interlanguage-link-target">فارسی</a></li><li class="interlanguage-link interwiki-fi"><a href="https://fi.wikipedia.org/wiki/Neuroverkot" title="Neuroverkot – Finnisch" lang="fi" hreflang="fi" class="interlanguage-link-target">Suomi</a></li><li class="interlanguage-link interwiki-fr"><a href="https://fr.wikipedia.org/wiki/R%C3%A9seau_de_neurones_artificiels" title="Réseau de neurones artificiels – Französisch" lang="fr" hreflang="fr" class="interlanguage-link-target">Français</a></li><li class="interlanguage-link interwiki-ga"><a href="https://ga.wikipedia.org/wiki/L%C3%ADonra_n%C3%A9arach_saorga" title="Líonra néarach saorga – Irisch" lang="ga" hreflang="ga" class="interlanguage-link-target">Gaeilge</a></li><li class="interlanguage-link interwiki-he"><a href="https://he.wikipedia.org/wiki/%D7%A8%D7%A9%D7%AA_%D7%A2%D7%A6%D7%91%D7%99%D7%AA_%D7%9E%D7%9C%D7%90%D7%9B%D7%95%D7%AA%D7%99%D7%AA" title="רשת עצבית מלאכותית – Hebräisch" lang="he" hreflang="he" class="interlanguage-link-target">עברית</a></li><li class="interlanguage-link interwiki-hi"><a href="https://hi.wikipedia.org/wiki/%E0%A4%95%E0%A5%83%E0%A4%A4%E0%A5%8D%E0%A4%B0%E0%A4%BF%E0%A4%AE_%E0%A4%A4%E0%A4%82%E0%A4%A4%E0%A5%8D%E0%A4%B0%E0%A4%BF%E0%A4%95%E0%A4%BE_%E0%A4%A8%E0%A5%87%E0%A4%9F%E0%A4%B5%E0%A4%B0%E0%A5%8D%E0%A4%95" title="कृत्रिम तंत्रिका नेटवर्क – Hindi" lang="hi" hreflang="hi" class="interlanguage-link-target">हिन्दी</a></li><li class="interlanguage-link interwiki-hr"><a href="https://hr.wikipedia.org/wiki/Umjetna_neuronska_mre%C5%BEa" title="Umjetna neuronska mreža – Kroatisch" lang="hr" hreflang="hr" class="interlanguage-link-target">Hrvatski</a></li><li class="interlanguage-link interwiki-hu"><a href="https://hu.wikipedia.org/wiki/Mesters%C3%A9ges_neur%C3%A1lis_h%C3%A1l%C3%B3zat" title="Mesterséges neurális hálózat – Ungarisch" lang="hu" hreflang="hu" class="interlanguage-link-target">Magyar</a></li><li class="interlanguage-link interwiki-hy"><a href="https://hy.wikipedia.org/wiki/%D4%B1%D6%80%D5%B0%D5%A5%D5%BD%D5%BF%D5%A1%D5%AF%D5%A1%D5%B6_%D5%B6%D5%A5%D5%B5%D6%80%D5%B8%D5%B6%D5%A1%D5%B5%D5%AB%D5%B6_%D6%81%D5%A1%D5%B6%D6%81" title="Արհեստական նեյրոնային ցանց – Armenisch" lang="hy" hreflang="hy" class="interlanguage-link-target">Հայերեն</a></li><li class="interlanguage-link interwiki-id"><a href="https://id.wikipedia.org/wiki/Jaringan_saraf_tiruan" title="Jaringan saraf tiruan – Indonesisch" lang="id" hreflang="id" class="interlanguage-link-target">Bahasa Indonesia</a></li><li class="interlanguage-link interwiki-is"><a href="https://is.wikipedia.org/wiki/Gervitauganet" title="Gervitauganet – Isländisch" lang="is" hreflang="is" class="interlanguage-link-target">Íslenska</a></li><li class="interlanguage-link interwiki-it"><a href="https://it.wikipedia.org/wiki/Rete_neurale_artificiale" title="Rete neurale artificiale – Italienisch" lang="it" hreflang="it" class="interlanguage-link-target">Italiano</a></li><li class="interlanguage-link interwiki-ja"><a href="https://ja.wikipedia.org/wiki/%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF" title="ニューラルネットワーク – Japanisch" lang="ja" hreflang="ja" class="interlanguage-link-target">日本語</a></li><li class="interlanguage-link interwiki-ka"><a href="https://ka.wikipedia.org/wiki/%E1%83%AE%E1%83%94%E1%83%9A%E1%83%9D%E1%83%95%E1%83%9C%E1%83%A3%E1%83%A0%E1%83%98_%E1%83%9C%E1%83%94%E1%83%98%E1%83%A0%E1%83%9D%E1%83%9C%E1%83%A3%E1%83%9A%E1%83%98_%E1%83%A5%E1%83%A1%E1%83%94%E1%83%9A%E1%83%98" title="ხელოვნური ნეირონული ქსელი – Georgisch" lang="ka" hreflang="ka" class="interlanguage-link-target">ქართული</a></li><li class="interlanguage-link interwiki-ko"><a href="https://ko.wikipedia.org/wiki/%EC%9D%B8%EA%B3%B5_%EC%8B%A0%EA%B2%BD%EB%A7%9D" title="인공 신경망 – Koreanisch" lang="ko" hreflang="ko" class="interlanguage-link-target">한국어</a></li><li class="interlanguage-link interwiki-la"><a href="https://la.wikipedia.org/wiki/Artificiale_neuronum_rete" title="Artificiale neuronum rete – Latein" lang="la" hreflang="la" class="interlanguage-link-target">Latina</a></li><li class="interlanguage-link interwiki-lt"><a href="https://lt.wikipedia.org/wiki/Dirbtinis_neuroninis_tinklas" title="Dirbtinis neuroninis tinklas – Litauisch" lang="lt" hreflang="lt" class="interlanguage-link-target">Lietuvių</a></li><li class="interlanguage-link interwiki-lv"><a href="https://lv.wikipedia.org/wiki/M%C4%81ksl%C4%ABgais_neironu_t%C4%ABkls" title="Mākslīgais neironu tīkls – Lettisch" lang="lv" hreflang="lv" class="interlanguage-link-target">Latviešu</a></li><li class="interlanguage-link interwiki-mg"><a href="https://mg.wikipedia.org/wiki/Tambajotra_ner%C3%B4nina" title="Tambajotra nerônina – Madagassisch" lang="mg" hreflang="mg" class="interlanguage-link-target">Malagasy</a></li><li class="interlanguage-link interwiki-mk"><a href="https://mk.wikipedia.org/wiki/%D0%92%D0%B5%D1%88%D1%82%D0%B0%D1%87%D0%BA%D0%B0_%D0%BD%D0%B5%D0%B2%D1%80%D0%BE%D0%BD%D1%81%D0%BA%D0%B0_%D0%BC%D1%80%D0%B5%D0%B6%D0%B0" title="Вештачка невронска мрежа – Mazedonisch" lang="mk" hreflang="mk" class="interlanguage-link-target">Македонски</a></li><li class="interlanguage-link interwiki-ml"><a href="https://ml.wikipedia.org/wiki/%E0%B4%95%E0%B5%83%E0%B4%A4%E0%B5%8D%E0%B4%B0%E0%B4%BF%E0%B4%AE_%E0%B4%A8%E0%B4%BE%E0%B4%A1%E0%B5%80%E0%B4%B5%E0%B5%8D%E0%B4%AF%E0%B5%82%E0%B4%B9%E0%B4%82" title="കൃത്രിമ നാഡീവ്യൂഹം – Malayalam" lang="ml" hreflang="ml" class="interlanguage-link-target">മലയാളം</a></li><li class="interlanguage-link interwiki-ms"><a href="https://ms.wikipedia.org/wiki/Rangkaian_neural_buatan" title="Rangkaian neural buatan – Malaiisch" lang="ms" hreflang="ms" class="interlanguage-link-target">Bahasa Melayu</a></li><li class="interlanguage-link interwiki-nn"><a href="https://nn.wikipedia.org/wiki/Kunstig_nevralt_nettverk" title="Kunstig nevralt nettverk – Norwegisch Nynorsk" lang="nn" hreflang="nn" class="interlanguage-link-target">Norsk nynorsk</a></li><li class="interlanguage-link interwiki-no"><a href="https://no.wikipedia.org/wiki/Kunstig_nevralt_nettverk" title="Kunstig nevralt nettverk – Norwegisch" lang="no" hreflang="no" class="interlanguage-link-target">Norsk</a></li><li class="interlanguage-link interwiki-or"><a href="https://or.wikipedia.org/wiki/%E0%AC%86%E0%AC%B0%E0%AD%8D%E0%AC%9F%E0%AC%BF%E0%AC%AB%E0%AC%BF%E0%AC%B8%E0%AC%BF%E0%AC%86%E0%AC%B2_%E0%AC%A8%E0%AD%8D%E0%AD%9F%E0%AD%81%E0%AC%B0%E0%AC%BE%E0%AC%B2_%E0%AC%A8%E0%AD%87%E0%AC%9F%E0%AD%B1%E0%AC%B0%E0%AD%8D%E0%AC%95" title="ଆର୍ଟିଫିସିଆଲ ନ୍ୟୁରାଲ ନେଟୱର୍କ – Oriya" lang="or" hreflang="or" class="interlanguage-link-target">ଓଡ଼ିଆ</a></li><li class="interlanguage-link interwiki-pl"><a href="https://pl.wikipedia.org/wiki/Sie%C4%87_neuronowa" title="Sieć neuronowa – Polnisch" lang="pl" hreflang="pl" class="interlanguage-link-target">Polski</a></li><li class="interlanguage-link interwiki-pt"><a href="https://pt.wikipedia.org/wiki/Rede_neural_artificial" title="Rede neural artificial – Portugiesisch" lang="pt" hreflang="pt" class="interlanguage-link-target">Português</a></li><li class="interlanguage-link interwiki-ro"><a href="https://ro.wikipedia.org/wiki/Re%C8%9Bea_neural%C4%83" title="Rețea neurală – Rumänisch" lang="ro" hreflang="ro" class="interlanguage-link-target">Română</a></li><li class="interlanguage-link interwiki-ru"><a href="https://ru.wikipedia.org/wiki/%D0%98%D1%81%D0%BA%D1%83%D1%81%D1%81%D1%82%D0%B2%D0%B5%D0%BD%D0%BD%D0%B0%D1%8F_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D0%B0%D1%8F_%D1%81%D0%B5%D1%82%D1%8C" title="Искусственная нейронная сеть – Russisch" lang="ru" hreflang="ru" class="interlanguage-link-target">Русский</a></li><li class="interlanguage-link interwiki-simple"><a href="https://simple.wikipedia.org/wiki/Artificial_neural_network" title="Artificial neural network – einfaches Englisch" lang="en-simple" hreflang="en-simple" class="interlanguage-link-target">Simple English</a></li><li class="interlanguage-link interwiki-sr"><a href="https://sr.wikipedia.org/wiki/Ve%C5%A1ta%C4%8Dka_neuronska_mre%C5%BEa" title="Veštačka neuronska mreža – Serbisch" lang="sr" hreflang="sr" class="interlanguage-link-target">Српски / srpski</a></li><li class="interlanguage-link interwiki-sv"><a href="https://sv.wikipedia.org/wiki/Artificiellt_neuronn%C3%A4t" title="Artificiellt neuronnät – Schwedisch" lang="sv" hreflang="sv" class="interlanguage-link-target">Svenska</a></li><li class="interlanguage-link interwiki-ta"><a href="https://ta.wikipedia.org/wiki/%E0%AE%9A%E0%AF%86%E0%AE%AF%E0%AE%B1%E0%AF%8D%E0%AE%95%E0%AF%88_%E0%AE%A8%E0%AE%B0%E0%AE%AE%E0%AF%8D%E0%AE%AA%E0%AE%A3%E0%AF%81%E0%AE%AA%E0%AF%8D_%E0%AE%AA%E0%AE%BF%E0%AE%A3%E0%AF%88%E0%AE%AF%E0%AE%AE%E0%AF%8D" title="செயற்கை நரம்பணுப் பிணையம் – Tamil" lang="ta" hreflang="ta" class="interlanguage-link-target">தமிழ்</a></li><li class="interlanguage-link interwiki-th"><a href="https://th.wikipedia.org/wiki/%E0%B9%82%E0%B8%84%E0%B8%A3%E0%B8%87%E0%B8%82%E0%B9%88%E0%B8%B2%E0%B8%A2%E0%B8%9B%E0%B8%A3%E0%B8%B0%E0%B8%AA%E0%B8%B2%E0%B8%97%E0%B9%80%E0%B8%97%E0%B8%B5%E0%B8%A2%E0%B8%A1" title="โครงข่ายประสาทเทียม – Thailändisch" lang="th" hreflang="th" class="interlanguage-link-target">ไทย</a></li><li class="interlanguage-link interwiki-tr"><a href="https://tr.wikipedia.org/wiki/Yapay_sinir_a%C4%9Flar%C4%B1" title="Yapay sinir ağları – Türkisch" lang="tr" hreflang="tr" class="interlanguage-link-target">Türkçe</a></li><li class="interlanguage-link interwiki-uk"><a href="https://uk.wikipedia.org/wiki/%D0%A8%D1%82%D1%83%D1%87%D0%BD%D0%B0_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D0%B0_%D0%BC%D0%B5%D1%80%D0%B5%D0%B6%D0%B0" title="Штучна нейронна мережа – Ukrainisch" lang="uk" hreflang="uk" class="interlanguage-link-target">Українська</a></li><li class="interlanguage-link interwiki-ur"><a href="https://ur.wikipedia.org/wiki/%D8%A7%D8%B5%D8%B7%D9%86%D8%A7%D8%B9%DB%8C_%D8%B9%D8%B5%D8%A8%DB%8C_%D8%AC%D8%A7%D9%84%DA%A9%D8%A7%D8%B1" title="اصطناعی عصبی جالکار – Urdu" lang="ur" hreflang="ur" class="interlanguage-link-target">اردو</a></li><li class="interlanguage-link interwiki-vi"><a href="https://vi.wikipedia.org/wiki/M%E1%BA%A1ng_n%C6%A1-ron_nh%C3%A2n_t%E1%BA%A1o" title="Mạng nơ-ron nhân tạo – Vietnamesisch" lang="vi" hreflang="vi" class="interlanguage-link-target">Tiếng Việt</a></li><li class="interlanguage-link interwiki-zh"><a href="https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C" title="人工神经网络 – Chinesisch" lang="zh" hreflang="zh" class="interlanguage-link-target">中文</a></li><li class="interlanguage-link interwiki-zh-min-nan"><a href="https://zh-min-nan.wikipedia.org/wiki/J%C3%AEn-kang_s%C3%AEn-keng_b%C4%81ng-l%C5%8D%CD%98" title="Jîn-kang sîn-keng bāng-lō͘ – Chinesisch (Min Nan)" lang="nan" hreflang="nan" class="interlanguage-link-target">Bân-lâm-gú</a></li><li class="interlanguage-link interwiki-zh-yue"><a href="https://zh-yue.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%B6%93%E7%B6%B2%E7%B5%A1" title="人工神經網絡 – Kantonesisch" lang="yue" hreflang="yue" class="interlanguage-link-target">粵語</a></li>				</ul>
				<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q192776#sitelinks-wikipedia" title="Links auf Artikel in anderen Sprachen bearbeiten" class="wbc-editpage">Links bearbeiten</a></span></div>			</div>
		</div>
				</div>
		</div>
				<div id="footer" role="contentinfo">
						<ul id="footer-info">
								<li id="footer-info-lastmod"> Diese Seite wurde zuletzt am 14. April 2019 um 16:35 Uhr bearbeitet.</li>
								<li id="footer-info-copyright"><div id="footer-info-copyright-stats" class="noprint"><a class="external" href="https://tools.wmflabs.org/pageviews?pages=K%C3%BCnstliches_neuronales_Netz&amp;project=de.wikipedia.org" rel="nofollow">Abrufstatistik</a></div><div id="footer-info-copyright-separator"><br /></div><div id="footer-info-copyright-info">
Der Text ist unter der Lizenz <a class="internal" href="https://de.wikipedia.org/wiki/Wikipedia:Lizenzbestimmungen_Commons_Attribution-ShareAlike_3.0_Unported">„Creative Commons Attribution/Share Alike“</a> verfügbar; Informationen zu den Urhebern und zum Lizenzstatus eingebundener Mediendateien (etwa Bilder oder Videos) können im Regelfall durch Anklicken dieser abgerufen werden. Möglicherweise unterliegen die Inhalte jeweils zusätzlichen Bedingungen. Durch die Nutzung dieser Website erklären Sie sich mit den <a class="internal" href="https://foundation.wikimedia.org/wiki/Terms_of_Use/de">Nutzungsbedingungen</a> und der <a class="internal" href="https://meta.wikimedia.org/wiki/Privacy_policy/de">Datenschutzrichtlinie</a> einverstanden.<br />
Wikipedia® ist eine eingetragene Marke der Wikimedia Foundation Inc.</div></li>
							</ul>
						<ul id="footer-places">
								<li id="footer-places-privacy"><a href="https://meta.wikimedia.org/wiki/Privacy_policy/de" class="extiw" title="m:Privacy policy/de">Datenschutz</a></li>
								<li id="footer-places-about"><a href="/wiki/Wikipedia:%C3%9Cber_Wikipedia" title="Wikipedia:Über Wikipedia">Über Wikipedia</a></li>
								<li id="footer-places-disclaimer"><a href="/wiki/Wikipedia:Impressum" title="Wikipedia:Impressum">Impressum</a></li>
								<li id="footer-places-developers"><a href="https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute">Entwickler</a></li>
								<li id="footer-places-cookiestatement"><a href="https://foundation.wikimedia.org/wiki/Cookie_statement">Stellungnahme zu Cookies</a></li>
								<li id="footer-places-mobileview"><a href="//de.m.wikipedia.org/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&amp;mobileaction=toggle_view_mobile" class="noprint stopMobileRedirectToggle">Mobile Ansicht</a></li>
							</ul>
										<ul id="footer-icons" class="noprint">
										<li id="footer-copyrightico">
						<a href="https://wikimediafoundation.org/"><img src="/static/images/wikimedia-button.png" srcset="/static/images/wikimedia-button-1.5x.png 1.5x, /static/images/wikimedia-button-2x.png 2x" width="88" height="31" alt="Wikimedia Foundation"/></a>					</li>
										<li id="footer-poweredbyico">
						<a href="//www.mediawiki.org/"><img src="/static/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" srcset="/static/images/poweredby_mediawiki_132x47.png 1.5x, /static/images/poweredby_mediawiki_176x62.png 2x" width="88" height="31"/></a>					</li>
									</ul>
						<div style="clear: both;"></div>
		</div>
		

<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgPageParseReport":{"limitreport":{"cputime":"0.692","walltime":"0.882","ppvisitednodes":{"value":2633,"limit":1000000},"ppgeneratednodes":{"value":0,"limit":1500000},"postexpandincludesize":{"value":25737,"limit":2097152},"templateargumentsize":{"value":5673,"limit":2097152},"expansiondepth":{"value":13,"limit":40},"expensivefunctioncount":{"value":5,"limit":500},"unstrip-depth":{"value":0,"limit":20},"unstrip-size":{"value":17997,"limit":5000000},"entityaccesscount":{"value":1,"limit":400},"timingprofile":["100.00%  609.699      1 -total"," 30.08%  183.378      4 Vorlage:Internetquelle"," 15.15%   92.393      1 Vorlage:Cite_journal"," 12.23%   74.569      1 Vorlage:Literatur"," 10.72%   65.332      2 Vorlage:Webarchiv","  9.01%   54.931      1 Vorlage:Normdaten","  7.44%   45.376      1 Vorlage:EnS","  7.43%   45.282      1 Vorlage:Wikidata-Registrierung","  5.48%   33.420      2 Vorlage:FormatDate","  4.13%   25.191      4 Vorlage:Str_len"]},"scribunto":{"limitreport-timeusage":{"value":"0.211","limit":"10.000"},"limitreport-memusage":{"value":5567328,"limit":52428800}},"cachereport":{"origin":"mw1240","timestamp":"20190430152710","ttl":2592000,"transientcontent":false}}});mw.config.set({"wgBackendResponseTime":1100,"wgHostname":"mw1240"});});</script>
</body>
</html>

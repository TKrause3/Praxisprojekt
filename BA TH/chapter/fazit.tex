%!TEX root = ../draft.tex
\chapter{Fazit}\label{s.fazit}
Zunächst wird auf die Anforderungen eingegangen und wie gut diese erfüllt werden konnten. Für ein abschließendes Fazit wird anschließend erläutert auf welche Art von Datensätze, die in dieser Arbeit untersuchten Normalisierungsverfahren angewendet werden können und wo die Schwächen liegen.\\\\
Bei der ersten Anforderung ging es um das Training des neuronalen Netzes und um eine Möglichkeit mit weniger Bildern pro Datensatz auszukommen. Dieser Punkt konnte erfüllt werden, indem vortrainierte künstliche neuronale Netze verwendet wurden. Dadurch sind die Mengen der Trainingsdaten auf durchschnittlich 200 Bilder pro Klasse gesunken.\\\\
Bei den Anforderungen zwei bis fünf wurden die Datensätze, welche bei dem Versuch verwendet werden sollten spezifiziert. Die Anforderung zwei, bei der es um die Ordentlichkeit der Datensätze. Diese wurde bei fast jedem Datensatz erfüllt. Lediglich der PascalVOC-Datensatz hat die Trainingsdaten gemischt und erschwert dadurch das Verändern der einzelnen Klassen. Die dritte Anforderung, in der es um die Größe der Bilder ging, wurde bei jedem Datensatz erfüllt. Die Bilder haben eine Größe zwischen 100-300 KB. Anforderung vier in der es um die Ausleuchtung der Trainingsdaten ging, wurde nur teilweise erfüllt, da für das Testen der neuronalen Netze auch schlecht ausgeleuchtete Testdaten benötigt wurden. Bei Anforderung fünf ging es um die Definition eines eingegrenzten Themas, der einzelnen Datensätze. Jeder Datensatz hatte ein gut definiertes Thema, welches unter anderem sehr ähnliche Klassen besaß. Beim PascalVOC-Datensatz war dieser teilweise ziemlich willkürlich, hat aber in der Klassifizierung relativ gut funktioniert.\\\\
Bei der Anforderungen sechs ging es um die Anwendung der Normalisierungsverfahren auf verschiedene Datensätze. Dabei sollte herausgestellt werden, ob und unter welchen Bedingungen eine Farbnormalisierung einen positiven Einfluss auf eine Klassifizierung durch neuronale Netze hat. Dabei sind je nach Normalisierungsverfahren unterschiedliche Ergebnisse entstanden, welche im Folgenden nacheinander behandelt werden.\\\\
\textbf{Gray-World-Algorithmus}\\
Der Gray-World-Algorithmus kann prinzipiell bei jedem Datensatz angewendet werden. Der Vorteil wird deutlich, wenn verschiedene Lichtfarben in der späteren Erkennung und im Datensatz auftauchen. Durch diese Methode werden Kontrast und Dynamik nicht verändert. Das Farbbild wird insgesamt auf Grundlage des Grünkanals verschoben. Da dieses Verfahren relativ simpel arbeitet, wird kein großer Einfluss auf spätere künstliche neuronale Netze erzielt.\\\\
\textbf{Histogramm-Ausgleich}\\
Der Histogramm-Ausgleich arbeitet auf Grundlage des Histogramms und versucht den Kontrast in dem Bild zu erhöhen. Eingesetzt werden kann es bei Datensätzen, welche einen einheitlichen Hintergrund verwenden, da für die Normalisierung die Farbverteilung des gesamten Bildes verwendet wird. Denn je nach Farbverteilung fällt das Ausgabebild, nach dem Ausgleich, unterschiedlich aus. Schwächen gibt es bei starken Lichtunterschieden. Sollte ein Bild zu dunkel sein, können Farbwerte nicht wiederhergestellt werden.\\\\
\textbf{Histogramm-Spezifizierung}\\
Auch die Histogramm-Spezifizierung ist nicht für allgemeine Datensätze geeignet, sondern für Datensätze mit einheitlichem Hintergrund. Das liegt zum einen an der Verarbeitung des Histogramms und zum anderen an der Tatsache, dass für dieses Verfahren ein Referenzbild benötigt wird, auf welchem der Datensatz normalisiert wird. Dieses Referenzbild ist effektiver, desto ähnlicher es dem Datensatz ist. Die Ergebnisse dieses Verfahrens haben beim Obst-Datensatz eine deutlich erhöhte Genauigkeit erzielt. Bei diesem Verfahren muss beachtet werden, dass es die längste Laufzeit hat und eine gewisse Arbeit voraussetzt.\\\\
In dieser Arbeit sollte überprüft werden, ob die Anwendung von Farbnormalisierungsalgorithmen einen positiven Einfluss auf die Genauigkeit der Klassifizierung, mittels künstliche neuronaler Netze, haben. Dabei ist herausgekommen, dass Farbnormalisierung einen positiven Einfluss haben kann. Wichtig dabei ist auf die Funktionsweise der Verfahren zu achten und zu prüfen für welche Szenarien diese sinnvoll eingesetzt werden können. Dafür ist es in manchen Fällen auch notwendig, die Datensätze an die Normalisierungen anzupassen.\\\\
Im  weiteren sollen Ansätze aufgeführt werden, die die Forschung nach dieser Arbeit weiter verfolgen kann. In dieser Arbeit wurden die Verfahren mit vortrainierten neuronalen Netzen überprüft. Es wäre daher eine interessante Frage, wie im Vergleich dazu untrainierte neuronale Netze die Verfahren beeinflussen. Zudem konnten im Rahmen dieser Bachelorarbeit nur Datensätze in der Mindestgröße generiert werden. Deswegen wäre es ebenso spannend herauszufinden, wie die Ergebnisse bei wesentlich größeren und ausführlicheren Datensätzen aussehen würden.\\
Außerdem könnte das Verhalten der Normalisierungsmethoden in Kombination miteinander untersucht werden. Möglicherweise können durch solche Kombinationen die unterschiedlichen Stärken der Verfahren genutzt werden.  

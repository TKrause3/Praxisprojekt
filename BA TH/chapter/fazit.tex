%!TEX root = ../draft.tex
\chapter{Fazit}\label{s.fazit}
Für ein abschließendes Fazit wird für jedes Normalisierungsverfahren erklärt für welche Art Datensätzen diese verwendet werden können und wo die Schwächen liegen. Zunächst wird aber auf die Anforderungen eingegangen und wie gut diese erfüllt werden konnten.\\\\
Bei dem ersten Punkt der Anforderungen, ging es um das Training des neuronalen Netzes und um eine Möglichkeit weniger Datensätze zu benötigen. Dieser Punkt konnte erfüllt werden, indem vortrainierte künstliche neuronale Netze verwendet wurden. Dadurch sind die mengen der Trainingsdaten auf durchschnittlich 200 Bildern pro Klasse gesunken.\\\\
Im nächsten Punkt, ging es um die Datensätze welche beim versuch verwendet werden. Die erste Anforderung an den Datensatz war die Ordentlichkeit. Dieser wurde bei fast jedem Datensatz erfüllt. Lediglich der PascalVOC Datensatz hat die Trainingsdaten gemischt und gibt dadurch wenig Möglichkeiten zum bearbeiten. Die zweite Anforderung wurde bei jedem Datensatz erfüllt und beinhalten Bilder in der Größe zwischen 100-300 KB. Der dritte Punkt wurde nur teilweise eingehalten, da für das Testen der neuronalen Netze auch schlecht ausgeleuchtete Testdaten benötigt wurden. Der letzte Punkt um den es gegangen ist, war die Definition eines eines eingegrenzten Themas der einzelnen Datensätze. Jeder Datensatz hatte ein gut definiertes Thema welches unter anderem sehr ähnliche Klassen besaßen. Beim PascalVOC Datensatz war dieser Teilweise ziemlich willkürlich, hat aber in der Klassifizierung relativ gut Funktioniert.\\\\
Bei dem letzten Punkt in den Anforderungen, ging es um die Anwendung der Normalisierungsverfahren auf die Datensätze. Dabei sollte herausgestellt werden, ob und unter welchen Anforderungen eine Farbnormalisierung einen Positiven Einfluss auf eine Klassifizierung durch neuronale Netze haben. Dabei sind je nach Normalisierungsverfahren unterschiedliche ergebnisse entstanden, welche im folgenden nacheinander behandelt werden.\\\\
\textbf{Gray-World-Algorithmus}\\
Der Gray-World-Algorithmus kann prinzipiell bei jedem Datensatz angewendet werden. Der Vorteil ist dann erkennbar, wenn verschiedene Lichtfarben in der späteren Erkennung und im Datensatz auftauchen können. Durch diese Methode wird der Kontrast und Dynamik nicht verändert. Das Farbbild wird insgesamt auf Grundlage des Grün-Kanals verschoben. Da dieses Verfahren relativ simpel arbeitet, wird kein großer Einfluss auf spätere künstliche neuronale Netze erzielt.\\\\
\textbf{Histogramm Ausgleich}\\
Der Histogramm Ausgleich arbeitet auf Grundlage des Histogramms und versucht den Kontrast in dem Bild zu erhöhen. Eingesetzt werden kann es bei Datensätzen, welche einen einheitlichen Hintergrund verwenden, da für die Normalisierung die Farbverteilung des gesamten Bildes verwendet wird. Denn je nach Farbverteilung fällt das Ausgabebild nach dem Ausgleich unterschiedlich aus. Schwächen entstehen bei starken Lichtunterschieden. Sollte ein Bild zu dunkel sein können Farbwerte nicht wiederhergestellt werden.\\\\
\textbf{Histogramm Spezifizierung}\\
Auch die Histogramm Spezifizierung ist nicht für allgemeine Datensätze geeignet, sondern bei Datensätzen mit einheitlichem Hintergrund. Das liegt zum einen an der Verarbeitung des Histogramms zum anderen an der Tatsache das für dieses Verfahren ein Referenzbild benötigt wird, auf welchem der Datensatz normalisiert wird. Dieses Referenzbild ist Effektiver, desto ähnlicher es dem Datensatz ist. Die Ergebnisse dieses Verfahrens, haben beim Obst Datensatz eine deutlich erhöhte Genauigkeit erzielt. Bei diesem muss aber beachtet werden, das die Laufzeit die längste war und eine gewisse Arbeit voraussetzt.\\\\
In dieser Arbeit, sollte überprüft werden ob die Anwendung von Farbnormalisierungsalgorithmen einen positiven Einfluss auf die Genauigkeit der Klassifizierung mittels künstliche neuronaler Netze haben. Dabei ist herausgekommen, das Farbnormalisierung einen positiven Einfluss haben kann. Wichtig dabei ist auf die Funktionsweise der Verfahren zu achten und für welche Szenarien diese sinnvoll eingesetzt werden. Dafür ist es, in manchen fällen auch notwendig, die Datensätze an die Normalisierungen anzupassen.\\\\
Im  weiteren, sollen Ansätze aufgeführt werden, in welche Richtung die Forschung nach dieser Arbeit weiter gehen könnte. Dafür werden einige Punkte aufgeführt. Die Verfahren wurden in dieser Arbeit mit vortrainierten neuronalen Netzen überprüft. Es wäre eine interessante frage welchen Einfluss diese Verfahren bei Entstehung der neuronalen Netze zu beobachten und welche Unterschiede dabei auftreten. Außerdem können für den Versuch mit einheitlichen Trainingsbildern größere Datensätze generiert und getestet werden. Im Rahmen dieser Bachelorarbeit konnte nur noch Trainingsdaten in der Mindestgröße erstellt werden. Interessant wäre es, wie sich die Genauigkeiten bei noch mehr Lichtvariationen verhalten würden.\\
Außerdem könnte das verhalten der Normalisierungsmethoden in Kombination miteinander untersucht werden. Beispielsweise wird mit der Histogramm Ausgleichung begonnen und mit einer Spezifikation kombiniert, wie in Kapitel \ref{s.hs} beschrieben. Durch solche Kombinationen könnten sich die unterschiedlichen stärken unterstützen.  